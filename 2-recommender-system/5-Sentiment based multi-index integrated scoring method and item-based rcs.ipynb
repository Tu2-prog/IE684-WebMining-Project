{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90395822-f83e-4b00-8644-39e2f265580d",
   "metadata": {},
   "source": [
    "# Sentiment based multi-index integrated scoring method to improve the accuracy of recommender system\n",
    "reference: https://www.sciencedirect.com/science/article/pii/S0957417421005467#b0230\n",
    "4.3. Multi-index integrated scoring method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b264e3-ddba-4722-a88d-0a1b882554dc",
   "metadata": {},
   "source": [
    "1. **Measure User Consistency per Aspect**\r\n",
    "\r\n",
    "    * For each user $u$ and aspect $a$, compute the Pearson correlation\r\n",
    "\r\n",
    "      $$\r\n",
    "      C_{u,a} = \\mathrm{Pearson}(\\{r_{u,i,a}\\},\\{s_{u,i,a}\\}).\r\n",
    "      $$  demonstrates more reliably on that aspect, all without any de-noising step.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa417c-574a-44fd-9335-0d23883f4f2d",
   "metadata": {},
   "source": [
    "2. **Derive an Adaptive Weight**\n",
    "\n",
    "   * Define\n",
    "\n",
    "     $$\n",
    "       w_{u,i,a} = 1 - C'_{u,a}.\n",
    "     $$\n",
    "   * Interpretation:\n",
    "\n",
    "     * **High consistency** ($C'\\approx1$) → $w\\approx0$ → default to the explicit rating.\n",
    "     * **Low consistency** → $w$ larger → rely more on sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd842ed-d640-4540-9e3f-da4b01b3aff4",
   "metadata": {},
   "source": [
    "3. **Fuse Rating & Sentiment per Aspect**\n",
    "\n",
    "   * Compute the final, blended score:\n",
    "\n",
    "     $$\n",
    "       r^*_{u,i,a}\n",
    "       = w_{u,i,a}\\,s_{u,i,a}\n",
    "       + (1 - w_{u,i,a})\\,r_{u,i,a}.\n",
    "     $$\n",
    "   * Each aspect gets its own adaptive mix of numeric rating and text-derived sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08252477-c1d8-4f3b-9cc7-51a4a27d1fc7",
   "metadata": {},
   "source": [
    "4. **Integrate into Recommendation**\n",
    "\n",
    "   * Treat the fused vector $\\{r^*_{u,i,1},\\dots,r^*_{u,i,A}\\}$ as the user’s multi-aspect preference.\n",
    "   * Plug this vector into your downstream model (e.g. multi-task matrix factorization or neural recommender).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d435f447-c003-4a57-8a24-10c4f221ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_predicted_rating</th>\n",
       "      <th>look_predicted_rating</th>\n",
       "      <th>smell_predicted_rating</th>\n",
       "      <th>taste_predicted_rating</th>\n",
       "      <th>feel_true_rating</th>\n",
       "      <th>look_true_rating</th>\n",
       "      <th>smell_true_rating</th>\n",
       "      <th>taste_true_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2beerdogs</td>\n",
       "      <td>286475</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scootny</td>\n",
       "      <td>138765</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boilermaker88</td>\n",
       "      <td>2280</td>\n",
       "      <td>2.054000</td>\n",
       "      <td>2.043250</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.063250</td>\n",
       "      <td>1.987500</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.525000</td>\n",
       "      <td>1.518750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altgeeky1</td>\n",
       "      <td>25007</td>\n",
       "      <td>2.377692</td>\n",
       "      <td>2.352308</td>\n",
       "      <td>2.366154</td>\n",
       "      <td>2.377692</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>2.807692</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>1.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>draheim</td>\n",
       "      <td>46983</td>\n",
       "      <td>3.997500</td>\n",
       "      <td>3.957500</td>\n",
       "      <td>4.007500</td>\n",
       "      <td>4.005000</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>metter98</td>\n",
       "      <td>51153</td>\n",
       "      <td>4.043333</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>4.046667</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>Gunslinger711</td>\n",
       "      <td>34146</td>\n",
       "      <td>3.844737</td>\n",
       "      <td>3.828947</td>\n",
       "      <td>3.843158</td>\n",
       "      <td>3.845789</td>\n",
       "      <td>3.921053</td>\n",
       "      <td>3.868421</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>4.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>9613</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>budgood1</td>\n",
       "      <td>31057</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21474</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>4137</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21475 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  beer_id  feel_predicted_rating  look_predicted_rating  \\\n",
       "0          2beerdogs   286475               3.820000               3.790000   \n",
       "1            scootny   138765               3.940000               3.930000   \n",
       "2      Boilermaker88     2280               2.054000               2.043250   \n",
       "3          altgeeky1    25007               2.377692               2.352308   \n",
       "4            draheim    46983               3.997500               3.957500   \n",
       "...              ...      ...                    ...                    ...   \n",
       "21470       metter98    51153               4.043333               4.040000   \n",
       "21471  Gunslinger711    34146               3.844737               3.828947   \n",
       "21472    BEERchitect     9613               3.070000               3.010000   \n",
       "21473       budgood1    31057               1.510000               1.530000   \n",
       "21474      roadhouse     4137               4.210000               4.220000   \n",
       "\n",
       "       smell_predicted_rating  taste_predicted_rating  feel_true_rating  \\\n",
       "0                    3.820000                3.840000          3.500000   \n",
       "1                    3.940000                3.940000          4.000000   \n",
       "2                    2.055000                2.063250          1.987500   \n",
       "3                    2.366154                2.377692          2.423077   \n",
       "4                    4.007500                4.005000          3.937500   \n",
       "...                       ...                     ...               ...   \n",
       "21470                4.060000                4.046667          4.083333   \n",
       "21471                3.843158                3.845789          3.921053   \n",
       "21472                3.040000                3.040000          3.000000   \n",
       "21473                1.520000                1.550000          1.500000   \n",
       "21474                4.220000                4.200000          4.000000   \n",
       "\n",
       "       look_true_rating  smell_true_rating  taste_true_rating  \n",
       "0              3.750000           3.750000           3.500000  \n",
       "1              3.625000           4.000000           4.125000  \n",
       "2              2.300000           1.525000           1.518750  \n",
       "3              2.807692           1.769231           1.884615  \n",
       "4              4.187500           4.187500           4.250000  \n",
       "...                 ...                ...                ...  \n",
       "21470          4.000000           4.416667           4.333333  \n",
       "21471          3.868421           3.934211           4.052632  \n",
       "21472          3.250000           3.250000           3.000000  \n",
       "21473          1.250000           1.500000           1.500000  \n",
       "21474          4.000000           3.500000           3.500000  \n",
       "\n",
       "[21475 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1) Load your pre-split data\n",
    "train_df = pd.read_csv(\"../Data/train_wide.csv\")  \n",
    "val_df   = pd.read_csv(\"../Data/test_wide.csv\")\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aabd3ba-c1bb-431b-82ec-10b072c28866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/rlj0hww930xfsv0_ns1r6c3w0000gn/T/ipykernel_83765/3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
      "/var/folders/kc/rlj0hww930xfsv0_ns1r6c3w0000gn/T/ipykernel_83765/3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
      "/var/folders/kc/rlj0hww930xfsv0_ns1r6c3w0000gn/T/ipykernel_83765/3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
      "/var/folders/kc/rlj0hww930xfsv0_ns1r6c3w0000gn/T/ipykernel_83765/3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1) List your aspects\n",
    "aspects = ['feel', 'look', 'smell', 'taste']\n",
    "\n",
    "# 2) Define a tiny helper that takes two numpy arrays and returns C'\n",
    "def cprime_from_arrays(tr, pr):\n",
    "    if tr.std() == 0 or pr.std() == 0:\n",
    "        # Euclidean-fallback\n",
    "        dist = np.linalg.norm(tr - pr)\n",
    "        return 1.0 / (1.0 + dist)\n",
    "    corr = pearsonr(tr, pr)[0]\n",
    "    return (corr + 1.0) / 2.0\n",
    "\n",
    "# 3) For each aspect, compute one C' per user, then map it back onto each row\n",
    "#    We'll also compute w and r_star in the same loop.\n",
    "for asp in aspects:\n",
    "    tcol = f'{asp}_true_rating'\n",
    "    pcol = f'{asp}_predicted_rating'\n",
    "    ccol = f'{asp}_C_prime'\n",
    "    wcol = f'{asp}_w'\n",
    "    rcol = f'{asp}_r_star'\n",
    "\n",
    "    # 3a) Compute the per-user scalar C'\n",
    "    #     groupby.apply returns a Series indexed by username\n",
    "    c_per_user = (\n",
    "        train_df\n",
    "        .groupby('username')\n",
    "        .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
    "    )\n",
    "\n",
    "    # 3b) Broadcast onto both train & val\n",
    "    train_df[ccol] = train_df['username'].map(c_per_user)\n",
    "    # for val, if a user never appeared in train, fill with the global mean\n",
    "    global_mean = c_per_user.mean()\n",
    "    val_df[ccol]   = val_df['username'].map(c_per_user).fillna(global_mean)\n",
    "\n",
    "    # 3c) Compute adaptive weight w = 1 – C'\n",
    "    train_df[wcol] = 1.0 - train_df[ccol]\n",
    "    val_df  [wcol] = 1.0 - val_df  [ccol]\n",
    "\n",
    "    # 3d) Fuse the scores\n",
    "    train_df[rcol] = train_df[wcol] * train_df[pcol] + (1.0 - train_df[wcol]) * train_df[tcol]\n",
    "    val_df  [rcol] = val_df  [wcol] * val_df  [pcol] + (1.0 - val_df  [wcol]) * val_df  [tcol]\n",
    "\n",
    "keep = ['username','beer_id'] + [f'{asp}_r_star' for asp in aspects]\n",
    "train_df = train_df[keep]\n",
    "val_df   = val_df[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592f389a-ac91-42db-ab17-643c7bf9bff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_r_star</th>\n",
       "      <th>look_r_star</th>\n",
       "      <th>smell_r_star</th>\n",
       "      <th>taste_r_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2beerdogs</td>\n",
       "      <td>286475</td>\n",
       "      <td>3.517751</td>\n",
       "      <td>3.760857</td>\n",
       "      <td>3.768435</td>\n",
       "      <td>3.551346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scootny</td>\n",
       "      <td>138765</td>\n",
       "      <td>3.984384</td>\n",
       "      <td>3.733674</td>\n",
       "      <td>3.991600</td>\n",
       "      <td>4.099598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boilermaker88</td>\n",
       "      <td>2280</td>\n",
       "      <td>1.989741</td>\n",
       "      <td>2.295181</td>\n",
       "      <td>1.553805</td>\n",
       "      <td>1.566540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altgeeky1</td>\n",
       "      <td>25007</td>\n",
       "      <td>2.417028</td>\n",
       "      <td>2.725218</td>\n",
       "      <td>1.784229</td>\n",
       "      <td>1.894806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>draheim</td>\n",
       "      <td>46983</td>\n",
       "      <td>3.949314</td>\n",
       "      <td>4.175389</td>\n",
       "      <td>4.156928</td>\n",
       "      <td>4.191522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>metter98</td>\n",
       "      <td>51153</td>\n",
       "      <td>4.079885</td>\n",
       "      <td>4.003453</td>\n",
       "      <td>4.388597</td>\n",
       "      <td>4.312034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>Gunslinger711</td>\n",
       "      <td>34146</td>\n",
       "      <td>3.915641</td>\n",
       "      <td>3.866922</td>\n",
       "      <td>3.926612</td>\n",
       "      <td>4.017181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>9613</td>\n",
       "      <td>3.008361</td>\n",
       "      <td>3.226066</td>\n",
       "      <td>3.227799</td>\n",
       "      <td>3.004243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>budgood1</td>\n",
       "      <td>31057</td>\n",
       "      <td>1.500929</td>\n",
       "      <td>1.270215</td>\n",
       "      <td>1.500857</td>\n",
       "      <td>1.504986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21474</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>4137</td>\n",
       "      <td>4.009236</td>\n",
       "      <td>4.018068</td>\n",
       "      <td>3.530114</td>\n",
       "      <td>3.528699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  beer_id  feel_r_star  look_r_star  smell_r_star  \\\n",
       "0          2beerdogs   286475     3.517751     3.760857      3.768435   \n",
       "1            scootny   138765     3.984384     3.733674      3.991600   \n",
       "2      Boilermaker88     2280     1.989741     2.295181      1.553805   \n",
       "3          altgeeky1    25007     2.417028     2.725218      1.784229   \n",
       "4            draheim    46983     3.949314     4.175389      4.156928   \n",
       "...              ...      ...          ...          ...           ...   \n",
       "21470       metter98    51153     4.079885     4.003453      4.388597   \n",
       "21471  Gunslinger711    34146     3.915641     3.866922      3.926612   \n",
       "21472    BEERchitect     9613     3.008361     3.226066      3.227799   \n",
       "21473       budgood1    31057     1.500929     1.270215      1.500857   \n",
       "21474      roadhouse     4137     4.009236     4.018068      3.530114   \n",
       "\n",
       "       taste_r_star  \n",
       "0          3.551346  \n",
       "1          4.099598  \n",
       "2          1.566540  \n",
       "3          1.894806  \n",
       "4          4.191522  \n",
       "...             ...  \n",
       "21470      4.312034  \n",
       "21471      4.017181  \n",
       "21472      3.004243  \n",
       "21473      1.504986  \n",
       "21474      3.528699  \n",
       "\n",
       "[21475 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f7f138-5ff8-4adc-b769-c026051e8e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_r_star</th>\n",
       "      <th>look_r_star</th>\n",
       "      <th>smell_r_star</th>\n",
       "      <th>taste_r_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>johnniemarg</td>\n",
       "      <td>9319</td>\n",
       "      <td>3.001225</td>\n",
       "      <td>3.949256</td>\n",
       "      <td>3.888750</td>\n",
       "      <td>3.977268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brolo75</td>\n",
       "      <td>207537</td>\n",
       "      <td>4.007071</td>\n",
       "      <td>4.033426</td>\n",
       "      <td>4.234354</td>\n",
       "      <td>4.222896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thehuntmaster</td>\n",
       "      <td>77779</td>\n",
       "      <td>2.012664</td>\n",
       "      <td>2.625627</td>\n",
       "      <td>2.248818</td>\n",
       "      <td>1.535139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Citadel82</td>\n",
       "      <td>29977</td>\n",
       "      <td>4.015398</td>\n",
       "      <td>4.011260</td>\n",
       "      <td>4.489105</td>\n",
       "      <td>4.471402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MattyG85</td>\n",
       "      <td>105784</td>\n",
       "      <td>4.360996</td>\n",
       "      <td>4.346861</td>\n",
       "      <td>4.247655</td>\n",
       "      <td>4.366067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>DIM</td>\n",
       "      <td>24905</td>\n",
       "      <td>3.897901</td>\n",
       "      <td>3.533755</td>\n",
       "      <td>3.897154</td>\n",
       "      <td>4.072123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>mfnmbvp</td>\n",
       "      <td>16807</td>\n",
       "      <td>3.712364</td>\n",
       "      <td>3.905960</td>\n",
       "      <td>4.099634</td>\n",
       "      <td>4.294318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>PhillyStyle</td>\n",
       "      <td>41505</td>\n",
       "      <td>3.146118</td>\n",
       "      <td>3.350885</td>\n",
       "      <td>3.221402</td>\n",
       "      <td>3.078893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>davidperez</td>\n",
       "      <td>74804</td>\n",
       "      <td>3.981646</td>\n",
       "      <td>3.847039</td>\n",
       "      <td>3.844615</td>\n",
       "      <td>3.707253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>eporter66</td>\n",
       "      <td>2751</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.119048</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5369 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username  beer_id  feel_r_star  look_r_star  smell_r_star  \\\n",
       "0       johnniemarg     9319     3.001225     3.949256      3.888750   \n",
       "1           Brolo75   207537     4.007071     4.033426      4.234354   \n",
       "2     Thehuntmaster    77779     2.012664     2.625627      2.248818   \n",
       "3         Citadel82    29977     4.015398     4.011260      4.489105   \n",
       "4          MattyG85   105784     4.360996     4.346861      4.247655   \n",
       "...             ...      ...          ...          ...           ...   \n",
       "5364            DIM    24905     3.897901     3.533755      3.897154   \n",
       "5365        mfnmbvp    16807     3.712364     3.905960      4.099634   \n",
       "5366    PhillyStyle    41505     3.146118     3.350885      3.221402   \n",
       "5367     davidperez    74804     3.981646     3.847039      3.844615   \n",
       "5368      eporter66     2751     4.083333     4.119048      4.000000   \n",
       "\n",
       "      taste_r_star  \n",
       "0         3.977268  \n",
       "1         4.222896  \n",
       "2         1.535139  \n",
       "3         4.471402  \n",
       "4         4.366067  \n",
       "...            ...  \n",
       "5364      4.072123  \n",
       "5365      4.294318  \n",
       "5366      3.078893  \n",
       "5367      3.707253  \n",
       "5368      4.095238  \n",
       "\n",
       "[5369 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000582b5-031e-4d26-894e-afb23b0c2067",
   "metadata": {},
   "source": [
    "# item-based-collaborative-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5df6829-ebae-47ac-a84d-162b681e7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/rlj0hww930xfsv0_ns1r6c3w0000gn/T/ipykernel_83765/3335527731.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['overall_r_star'] = train_df[[f'{asp}_r_star' for asp in aspects]].mean(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_r_star</th>\n",
       "      <th>look_r_star</th>\n",
       "      <th>smell_r_star</th>\n",
       "      <th>taste_r_star</th>\n",
       "      <th>overall_r_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2beerdogs</td>\n",
       "      <td>286475</td>\n",
       "      <td>3.517751</td>\n",
       "      <td>3.760857</td>\n",
       "      <td>3.768435</td>\n",
       "      <td>3.551346</td>\n",
       "      <td>3.649597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scootny</td>\n",
       "      <td>138765</td>\n",
       "      <td>3.984384</td>\n",
       "      <td>3.733674</td>\n",
       "      <td>3.991600</td>\n",
       "      <td>4.099598</td>\n",
       "      <td>3.952314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boilermaker88</td>\n",
       "      <td>2280</td>\n",
       "      <td>1.989741</td>\n",
       "      <td>2.295181</td>\n",
       "      <td>1.553805</td>\n",
       "      <td>1.566540</td>\n",
       "      <td>1.851317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altgeeky1</td>\n",
       "      <td>25007</td>\n",
       "      <td>2.417028</td>\n",
       "      <td>2.725218</td>\n",
       "      <td>1.784229</td>\n",
       "      <td>1.894806</td>\n",
       "      <td>2.205320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>draheim</td>\n",
       "      <td>46983</td>\n",
       "      <td>3.949314</td>\n",
       "      <td>4.175389</td>\n",
       "      <td>4.156928</td>\n",
       "      <td>4.191522</td>\n",
       "      <td>4.118288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>metter98</td>\n",
       "      <td>51153</td>\n",
       "      <td>4.079885</td>\n",
       "      <td>4.003453</td>\n",
       "      <td>4.388597</td>\n",
       "      <td>4.312034</td>\n",
       "      <td>4.195992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>Gunslinger711</td>\n",
       "      <td>34146</td>\n",
       "      <td>3.915641</td>\n",
       "      <td>3.866922</td>\n",
       "      <td>3.926612</td>\n",
       "      <td>4.017181</td>\n",
       "      <td>3.931589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>9613</td>\n",
       "      <td>3.008361</td>\n",
       "      <td>3.226066</td>\n",
       "      <td>3.227799</td>\n",
       "      <td>3.004243</td>\n",
       "      <td>3.116617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>budgood1</td>\n",
       "      <td>31057</td>\n",
       "      <td>1.500929</td>\n",
       "      <td>1.270215</td>\n",
       "      <td>1.500857</td>\n",
       "      <td>1.504986</td>\n",
       "      <td>1.444247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21474</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>4137</td>\n",
       "      <td>4.009236</td>\n",
       "      <td>4.018068</td>\n",
       "      <td>3.530114</td>\n",
       "      <td>3.528699</td>\n",
       "      <td>3.771529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  beer_id  feel_r_star  look_r_star  smell_r_star  \\\n",
       "0          2beerdogs   286475     3.517751     3.760857      3.768435   \n",
       "1            scootny   138765     3.984384     3.733674      3.991600   \n",
       "2      Boilermaker88     2280     1.989741     2.295181      1.553805   \n",
       "3          altgeeky1    25007     2.417028     2.725218      1.784229   \n",
       "4            draheim    46983     3.949314     4.175389      4.156928   \n",
       "...              ...      ...          ...          ...           ...   \n",
       "21470       metter98    51153     4.079885     4.003453      4.388597   \n",
       "21471  Gunslinger711    34146     3.915641     3.866922      3.926612   \n",
       "21472    BEERchitect     9613     3.008361     3.226066      3.227799   \n",
       "21473       budgood1    31057     1.500929     1.270215      1.500857   \n",
       "21474      roadhouse     4137     4.009236     4.018068      3.530114   \n",
       "\n",
       "       taste_r_star  overall_r_star  \n",
       "0          3.551346        3.649597  \n",
       "1          4.099598        3.952314  \n",
       "2          1.566540        1.851317  \n",
       "3          1.894806        2.205320  \n",
       "4          4.191522        4.118288  \n",
       "...             ...             ...  \n",
       "21470      4.312034        4.195992  \n",
       "21471      4.017181        3.931589  \n",
       "21472      3.004243        3.116617  \n",
       "21473      1.504986        1.444247  \n",
       "21474      3.528699        3.771529  \n",
       "\n",
       "[21475 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects = ['feel', 'look', 'smell', 'taste']\n",
    "train_df['overall_r_star'] = train_df[[f'{asp}_r_star' for asp in aspects]].mean(axis=1)\n",
    "val_df  ['overall_r_star'] = val_df  [[f'{asp}_r_star' for asp in aspects]].mean(axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a7583d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best RMSE score: 0.8670582197175598\n",
      "Best parameters: {'k': 10, 'min_k': 1, 'sim_options': {'name': 'pearson', 'user_based': False}}\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Surprise dataset using user-item-rating triples\n",
    "reader = Reader(rating_scale=(train_df['overall_r_star'].min(),\n",
    "                              train_df['overall_r_star'].max()))\n",
    "data = Dataset.load_from_df(\n",
    "    train_df[['username', 'beer_id', 'overall_r_star']],\n",
    "    reader\n",
    ")\n",
    "\n",
    "# Define parameter grid for GridSearch with item-based collaborative filtering\n",
    "param_grid = {\n",
    "    'k': [5, 10, 20, 40],\n",
    "    'min_k': [1, 2, 5],\n",
    "    'sim_options': {\n",
    "        'name': ['pearson', 'cosine'],\n",
    "        'user_based': [False]  # Use item-based similarity\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "gs = GridSearchCV(\n",
    "    KNNBasic,\n",
    "    param_grid,\n",
    "    measures=['rmse'],\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "gs.fit(data)\n",
    "\n",
    "# Output best results\n",
    "print(\"Best RMSE score:\", gs.best_score['rmse'])\n",
    "print(\"Best parameters:\", gs.best_params['rmse'])\n",
    "\n",
    "# Build final model using the best parameters\n",
    "trainset = data.build_full_trainset()\n",
    "best_opts = gs.best_params['rmse']\n",
    "algo = KNNBasic(\n",
    "    k=best_opts['k'],\n",
    "    min_k=best_opts['min_k'],\n",
    "    sim_options=best_opts['sim_options']\n",
    ")\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Prepare test data from validation set\n",
    "val_test_list = list(\n",
    "    val_df[['username', 'beer_id', 'overall_r_star']].itertuples(index=False, name=None)\n",
    ")\n",
    "predictions = algo.test(val_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3671791a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from surprise.accuracy import mse, rmse, mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mse_score  = mse(predictions, verbose=False)\n",
    "rmse_score = rmse(predictions, verbose=False)\n",
    "mae_score  = mae(predictions, verbose=False)\n",
    "\n",
    "metrics = ['MSE','RMSE','MAE']\n",
    "scores  = [mse_score, rmse_score, mae_score]\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.bar(metrics, scores)\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(i, v + 0.02, f\"{v:.3f}\", ha='center', va='bottom', fontweight='bold')\n",
    "ax.set_ylabel(\"Error\"); ax.set_title(\"Validation Set Performance\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94fd6127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 recommendations for Boilermaker88:\n",
      "  Beer 131: 4.477\n",
      "  Beer 466: 3.531\n",
      "  Beer 286475: 3.257\n",
      "  Beer 138765: 3.257\n",
      "  Beer 25007: 3.257\n",
      "\n",
      "Top-5 recommendations for budgood1:\n",
      "  Beer 1904: 4.267\n",
      "  Beer 435: 4.267\n",
      "  Beer 1716: 4.267\n",
      "  Beer 45653: 4.267\n",
      "  Beer 83599: 4.267\n",
      "\n",
      "Top-5 recommendations for draheim:\n",
      "  Beer 286475: 3.257\n",
      "  Beer 138765: 3.257\n",
      "  Beer 2280: 3.257\n",
      "  Beer 25007: 3.257\n",
      "  Beer 28248: 3.257\n"
     ]
    }
   ],
   "source": [
    "# Recommend top-N items for a given user using item-based model\n",
    "def recommend_user(algo, trainset, user_id, N=5):\n",
    "    \"\"\"\n",
    "    Returns a list of (item_id, estimated_score) for the top-N\n",
    "    items the user has not yet rated.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inner_uid = trainset.to_inner_uid(user_id)\n",
    "    except ValueError:\n",
    "        return []  # user not in trainset\n",
    "\n",
    "    # Items already rated by the user\n",
    "    seen_iids = {iid for (iid, _) in trainset.ur[inner_uid]}\n",
    "    raw_iids = [trainset.to_raw_iid(i) for i in trainset.all_items()]\n",
    "\n",
    "    # Recommend items not yet rated\n",
    "    candidates = [iid for iid in raw_iids if trainset.to_inner_iid(iid) not in seen_iids]\n",
    "    scores = [(iid, algo.predict(user_id, iid).est) for iid in candidates]\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:N]\n",
    "\n",
    "for user in ['Boilermaker88', 'budgood1', 'draheim']:\n",
    "    top5 = recommend_user(algo, trainset, user, N=5)\n",
    "    print(f\"\\nTop-5 recommendations for {user}:\")\n",
    "    for beer_id, score in top5:\n",
    "        print(f\"  Beer {beer_id}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ad0489-3fbe-441c-bfed-2b70887e8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 recommendations for Boilermaker88:\n",
      "  Beer 131: 4.477\n",
      "  Beer 466: 3.531\n",
      "  Beer 286475: 3.257\n",
      "  Beer 138765: 3.257\n",
      "  Beer 25007: 3.257\n",
      "\n",
      "Top-5 recommendations for budgood1:\n",
      "  Beer 1904: 4.267\n",
      "  Beer 435: 4.267\n",
      "  Beer 1716: 4.267\n",
      "  Beer 45653: 4.267\n",
      "  Beer 83599: 4.267\n",
      "\n",
      "Top-5 recommendations for draheim:\n",
      "  Beer 286475: 3.257\n",
      "  Beer 138765: 3.257\n",
      "  Beer 2280: 3.257\n",
      "  Beer 25007: 3.257\n",
      "  Beer 28248: 3.257\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "def recommend_user(algo, trainset, user_id, N=5):\n",
    "    \"\"\"\n",
    "    Returns a list of (item_id, estimated_score) for the top-N\n",
    "    items the user has not yet rated.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inner_uid = trainset.to_inner_uid(user_id)\n",
    "    except ValueError:\n",
    "        return []  # user not in trainset\n",
    "\n",
    "    # items the user has already rated\n",
    "    seen_iids = {iid for (iid, _) in trainset.ur[inner_uid]}\n",
    "    # map all internal iids back to raw ids\n",
    "    raw_iids = [trainset.to_raw_iid(i) for i in trainset.all_items()]\n",
    "\n",
    "    # candidates = those the user hasn't seen\n",
    "    candidates = [iid for iid in raw_iids if trainset.to_inner_iid(iid) not in seen_iids]\n",
    "\n",
    "    # predict each candidate\n",
    "    scores = [(iid, algo.predict(user_id, iid).est) for iid in candidates]\n",
    "    # sort by score descending and take top N\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:N]\n",
    "\n",
    "for user in ['Boilermaker88', 'budgood1', 'draheim']:\n",
    "    top5 = recommend_user(algo, trainset, user, N=5)\n",
    "    print(f\"\\nTop-5 recommendations for {user}:\")\n",
    "    for beer_id, score in top5:\n",
    "        print(f\"  Beer {beer_id}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1d403-eaae-4569-8808-159a59d74c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
