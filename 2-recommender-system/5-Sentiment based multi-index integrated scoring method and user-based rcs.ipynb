{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90395822-f83e-4b00-8644-39e2f265580d",
   "metadata": {},
   "source": [
    "# Sentiment based multi-index integrated scoring method to improve the accuracy of recommender system\n",
    "reference: https://www.sciencedirect.com/science/article/pii/S0957417421005467#b0230\n",
    "4.3. Multi-index integrated scoring method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b264e3-ddba-4722-a88d-0a1b882554dc",
   "metadata": {},
   "source": [
    "1. **Measure User Consistency per Aspect**\r\n",
    "\r\n",
    "    * For each user $u$ and aspect $a$, compute the Pearson correlation\r\n",
    "\r\n",
    "      $$\r\n",
    "      C_{u,a} = \\mathrm{Pearson}(\\{r_{u,i,a}\\},\\{s_{u,i,a}\\}).\r\n",
    "      $$  demonstrates more reliably on that aspect, all without any de-noising step.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa417c-574a-44fd-9335-0d23883f4f2d",
   "metadata": {},
   "source": [
    "2. **Derive an Adaptive Weight**\n",
    "\n",
    "   * Define\n",
    "\n",
    "     $$\n",
    "       w_{u,i,a} = 1 - C'_{u,a}.\n",
    "     $$\n",
    "   * Interpretation:\n",
    "\n",
    "     * **High consistency** ($C'\\approx1$) → $w\\approx0$ → default to the explicit rating.\n",
    "     * **Low consistency** → $w$ larger → rely more on sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd842ed-d640-4540-9e3f-da4b01b3aff4",
   "metadata": {},
   "source": [
    "3. **Fuse Rating & Sentiment per Aspect**\n",
    "\n",
    "   * Compute the final, blended score:\n",
    "\n",
    "     $$\n",
    "       r^*_{u,i,a}\n",
    "       = w_{u,i,a}\\,s_{u,i,a}\n",
    "       + (1 - w_{u,i,a})\\,r_{u,i,a}.\n",
    "     $$\n",
    "   * Each aspect gets its own adaptive mix of numeric rating and text-derived sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08252477-c1d8-4f3b-9cc7-51a4a27d1fc7",
   "metadata": {},
   "source": [
    "4. **Integrate into Recommendation**\n",
    "\n",
    "   * Treat the fused vector $\\{r^*_{u,i,1},\\dots,r^*_{u,i,A}\\}$ as the user’s multi-aspect preference.\n",
    "   * Plug this vector into your downstream model (e.g. multi-task matrix factorization or neural recommender).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d435f447-c003-4a57-8a24-10c4f221ae70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_predicted_rating</th>\n",
       "      <th>look_predicted_rating</th>\n",
       "      <th>smell_predicted_rating</th>\n",
       "      <th>taste_predicted_rating</th>\n",
       "      <th>feel_true_rating</th>\n",
       "      <th>look_true_rating</th>\n",
       "      <th>smell_true_rating</th>\n",
       "      <th>taste_true_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2beerdogs</td>\n",
       "      <td>286475</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.790000</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scootny</td>\n",
       "      <td>138765</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boilermaker88</td>\n",
       "      <td>2280</td>\n",
       "      <td>2.054000</td>\n",
       "      <td>2.043250</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>2.063250</td>\n",
       "      <td>1.987500</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.525000</td>\n",
       "      <td>1.518750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altgeeky1</td>\n",
       "      <td>25007</td>\n",
       "      <td>2.377692</td>\n",
       "      <td>2.352308</td>\n",
       "      <td>2.366154</td>\n",
       "      <td>2.377692</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>2.807692</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>1.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>draheim</td>\n",
       "      <td>46983</td>\n",
       "      <td>3.997500</td>\n",
       "      <td>3.957500</td>\n",
       "      <td>4.007500</td>\n",
       "      <td>4.005000</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>4.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>metter98</td>\n",
       "      <td>51153</td>\n",
       "      <td>4.043333</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4.060000</td>\n",
       "      <td>4.046667</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>Gunslinger711</td>\n",
       "      <td>34146</td>\n",
       "      <td>3.844737</td>\n",
       "      <td>3.828947</td>\n",
       "      <td>3.843158</td>\n",
       "      <td>3.845789</td>\n",
       "      <td>3.921053</td>\n",
       "      <td>3.868421</td>\n",
       "      <td>3.934211</td>\n",
       "      <td>4.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>9613</td>\n",
       "      <td>3.070000</td>\n",
       "      <td>3.010000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>budgood1</td>\n",
       "      <td>31057</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21474</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>4137</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>4.220000</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21475 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  beer_id  feel_predicted_rating  look_predicted_rating  \\\n",
       "0          2beerdogs   286475               3.820000               3.790000   \n",
       "1            scootny   138765               3.940000               3.930000   \n",
       "2      Boilermaker88     2280               2.054000               2.043250   \n",
       "3          altgeeky1    25007               2.377692               2.352308   \n",
       "4            draheim    46983               3.997500               3.957500   \n",
       "...              ...      ...                    ...                    ...   \n",
       "21470       metter98    51153               4.043333               4.040000   \n",
       "21471  Gunslinger711    34146               3.844737               3.828947   \n",
       "21472    BEERchitect     9613               3.070000               3.010000   \n",
       "21473       budgood1    31057               1.510000               1.530000   \n",
       "21474      roadhouse     4137               4.210000               4.220000   \n",
       "\n",
       "       smell_predicted_rating  taste_predicted_rating  feel_true_rating  \\\n",
       "0                    3.820000                3.840000          3.500000   \n",
       "1                    3.940000                3.940000          4.000000   \n",
       "2                    2.055000                2.063250          1.987500   \n",
       "3                    2.366154                2.377692          2.423077   \n",
       "4                    4.007500                4.005000          3.937500   \n",
       "...                       ...                     ...               ...   \n",
       "21470                4.060000                4.046667          4.083333   \n",
       "21471                3.843158                3.845789          3.921053   \n",
       "21472                3.040000                3.040000          3.000000   \n",
       "21473                1.520000                1.550000          1.500000   \n",
       "21474                4.220000                4.200000          4.000000   \n",
       "\n",
       "       look_true_rating  smell_true_rating  taste_true_rating  \n",
       "0              3.750000           3.750000           3.500000  \n",
       "1              3.625000           4.000000           4.125000  \n",
       "2              2.300000           1.525000           1.518750  \n",
       "3              2.807692           1.769231           1.884615  \n",
       "4              4.187500           4.187500           4.250000  \n",
       "...                 ...                ...                ...  \n",
       "21470          4.000000           4.416667           4.333333  \n",
       "21471          3.868421           3.934211           4.052632  \n",
       "21472          3.250000           3.250000           3.000000  \n",
       "21473          1.250000           1.500000           1.500000  \n",
       "21474          4.000000           3.500000           3.500000  \n",
       "\n",
       "[21475 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1) Load your pre-split data\n",
    "train_df = pd.read_csv(\"train_wide.csv\")  \n",
    "val_df   = pd.read_csv(\"test_wide.csv\")\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9aabd3ba-c1bb-431b-82ec-10b072c28866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\胖头鱼\\AppData\\Local\\Temp\\ipykernel_12772\\3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
      "C:\\Users\\胖头鱼\\AppData\\Local\\Temp\\ipykernel_12772\\3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
      "C:\\Users\\胖头鱼\\AppData\\Local\\Temp\\ipykernel_12772\\3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
      "C:\\Users\\胖头鱼\\AppData\\Local\\Temp\\ipykernel_12772\\3926633288.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1) List your aspects\n",
    "aspects = ['feel', 'look', 'smell', 'taste']\n",
    "\n",
    "# 2) Define a tiny helper that takes two numpy arrays and returns C'\n",
    "def cprime_from_arrays(tr, pr):\n",
    "    if tr.std() == 0 or pr.std() == 0:\n",
    "        # Euclidean-fallback\n",
    "        dist = np.linalg.norm(tr - pr)\n",
    "        return 1.0 / (1.0 + dist)\n",
    "    corr = pearsonr(tr, pr)[0]\n",
    "    return (corr + 1.0) / 2.0\n",
    "\n",
    "# 3) For each aspect, compute one C' per user, then map it back onto each row\n",
    "#    We'll also compute w and r_star in the same loop.\n",
    "for asp in aspects:\n",
    "    tcol = f'{asp}_true_rating'\n",
    "    pcol = f'{asp}_predicted_rating'\n",
    "    ccol = f'{asp}_C_prime'\n",
    "    wcol = f'{asp}_w'\n",
    "    rcol = f'{asp}_r_star'\n",
    "\n",
    "    # 3a) Compute the per-user scalar C'\n",
    "    #     groupby.apply returns a Series indexed by username\n",
    "    c_per_user = (\n",
    "        train_df\n",
    "        .groupby('username')\n",
    "        .apply(lambda g: cprime_from_arrays(g[tcol].values, g[pcol].values))\n",
    "    )\n",
    "\n",
    "    # 3b) Broadcast onto both train & val\n",
    "    train_df[ccol] = train_df['username'].map(c_per_user)\n",
    "    # for val, if a user never appeared in train, fill with the global mean\n",
    "    global_mean = c_per_user.mean()\n",
    "    val_df[ccol]   = val_df['username'].map(c_per_user).fillna(global_mean)\n",
    "\n",
    "    # 3c) Compute adaptive weight w = 1 – C'\n",
    "    train_df[wcol] = 1.0 - train_df[ccol]\n",
    "    val_df  [wcol] = 1.0 - val_df  [ccol]\n",
    "\n",
    "    # 3d) Fuse the scores\n",
    "    train_df[rcol] = train_df[wcol] * train_df[pcol] + (1.0 - train_df[wcol]) * train_df[tcol]\n",
    "    val_df  [rcol] = val_df  [wcol] * val_df  [pcol] + (1.0 - val_df  [wcol]) * val_df  [tcol]\n",
    "\n",
    "keep = ['username','beer_id'] + [f'{asp}_r_star' for asp in aspects]\n",
    "train_df = train_df[keep]\n",
    "val_df   = val_df[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "592f389a-ac91-42db-ab17-643c7bf9bff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_r_star</th>\n",
       "      <th>look_r_star</th>\n",
       "      <th>smell_r_star</th>\n",
       "      <th>taste_r_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2beerdogs</td>\n",
       "      <td>286475</td>\n",
       "      <td>3.517751</td>\n",
       "      <td>3.760857</td>\n",
       "      <td>3.768435</td>\n",
       "      <td>3.551346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scootny</td>\n",
       "      <td>138765</td>\n",
       "      <td>3.984384</td>\n",
       "      <td>3.733674</td>\n",
       "      <td>3.991600</td>\n",
       "      <td>4.099598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boilermaker88</td>\n",
       "      <td>2280</td>\n",
       "      <td>1.989741</td>\n",
       "      <td>2.295181</td>\n",
       "      <td>1.553805</td>\n",
       "      <td>1.566540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altgeeky1</td>\n",
       "      <td>25007</td>\n",
       "      <td>2.417028</td>\n",
       "      <td>2.725218</td>\n",
       "      <td>1.784229</td>\n",
       "      <td>1.894806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>draheim</td>\n",
       "      <td>46983</td>\n",
       "      <td>3.949314</td>\n",
       "      <td>4.175389</td>\n",
       "      <td>4.156928</td>\n",
       "      <td>4.191522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>metter98</td>\n",
       "      <td>51153</td>\n",
       "      <td>4.079885</td>\n",
       "      <td>4.003453</td>\n",
       "      <td>4.388597</td>\n",
       "      <td>4.312034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>Gunslinger711</td>\n",
       "      <td>34146</td>\n",
       "      <td>3.915641</td>\n",
       "      <td>3.866922</td>\n",
       "      <td>3.926612</td>\n",
       "      <td>4.017181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>9613</td>\n",
       "      <td>3.008361</td>\n",
       "      <td>3.226066</td>\n",
       "      <td>3.227799</td>\n",
       "      <td>3.004243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>budgood1</td>\n",
       "      <td>31057</td>\n",
       "      <td>1.500929</td>\n",
       "      <td>1.270215</td>\n",
       "      <td>1.500857</td>\n",
       "      <td>1.504986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21474</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>4137</td>\n",
       "      <td>4.009236</td>\n",
       "      <td>4.018068</td>\n",
       "      <td>3.530114</td>\n",
       "      <td>3.528699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21475 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  beer_id  feel_r_star  look_r_star  smell_r_star  \\\n",
       "0          2beerdogs   286475     3.517751     3.760857      3.768435   \n",
       "1            scootny   138765     3.984384     3.733674      3.991600   \n",
       "2      Boilermaker88     2280     1.989741     2.295181      1.553805   \n",
       "3          altgeeky1    25007     2.417028     2.725218      1.784229   \n",
       "4            draheim    46983     3.949314     4.175389      4.156928   \n",
       "...              ...      ...          ...          ...           ...   \n",
       "21470       metter98    51153     4.079885     4.003453      4.388597   \n",
       "21471  Gunslinger711    34146     3.915641     3.866922      3.926612   \n",
       "21472    BEERchitect     9613     3.008361     3.226066      3.227799   \n",
       "21473       budgood1    31057     1.500929     1.270215      1.500857   \n",
       "21474      roadhouse     4137     4.009236     4.018068      3.530114   \n",
       "\n",
       "       taste_r_star  \n",
       "0          3.551346  \n",
       "1          4.099598  \n",
       "2          1.566540  \n",
       "3          1.894806  \n",
       "4          4.191522  \n",
       "...             ...  \n",
       "21470      4.312034  \n",
       "21471      4.017181  \n",
       "21472      3.004243  \n",
       "21473      1.504986  \n",
       "21474      3.528699  \n",
       "\n",
       "[21475 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75f7f138-5ff8-4adc-b769-c026051e8e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_r_star</th>\n",
       "      <th>look_r_star</th>\n",
       "      <th>smell_r_star</th>\n",
       "      <th>taste_r_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>johnniemarg</td>\n",
       "      <td>9319</td>\n",
       "      <td>3.001225</td>\n",
       "      <td>3.949256</td>\n",
       "      <td>3.888750</td>\n",
       "      <td>3.977268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brolo75</td>\n",
       "      <td>207537</td>\n",
       "      <td>4.007071</td>\n",
       "      <td>4.033426</td>\n",
       "      <td>4.234354</td>\n",
       "      <td>4.222896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thehuntmaster</td>\n",
       "      <td>77779</td>\n",
       "      <td>2.012664</td>\n",
       "      <td>2.625627</td>\n",
       "      <td>2.248818</td>\n",
       "      <td>1.535139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Citadel82</td>\n",
       "      <td>29977</td>\n",
       "      <td>4.015398</td>\n",
       "      <td>4.011260</td>\n",
       "      <td>4.489105</td>\n",
       "      <td>4.471402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MattyG85</td>\n",
       "      <td>105784</td>\n",
       "      <td>4.360996</td>\n",
       "      <td>4.346861</td>\n",
       "      <td>4.247655</td>\n",
       "      <td>4.366067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>DIM</td>\n",
       "      <td>24905</td>\n",
       "      <td>3.897901</td>\n",
       "      <td>3.533755</td>\n",
       "      <td>3.897154</td>\n",
       "      <td>4.072123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>mfnmbvp</td>\n",
       "      <td>16807</td>\n",
       "      <td>3.712364</td>\n",
       "      <td>3.905960</td>\n",
       "      <td>4.099634</td>\n",
       "      <td>4.294318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>PhillyStyle</td>\n",
       "      <td>41505</td>\n",
       "      <td>3.146118</td>\n",
       "      <td>3.350885</td>\n",
       "      <td>3.221402</td>\n",
       "      <td>3.078893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>davidperez</td>\n",
       "      <td>74804</td>\n",
       "      <td>3.981646</td>\n",
       "      <td>3.847039</td>\n",
       "      <td>3.844615</td>\n",
       "      <td>3.707253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5368</th>\n",
       "      <td>eporter66</td>\n",
       "      <td>2751</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.119048</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5369 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username  beer_id  feel_r_star  look_r_star  smell_r_star  \\\n",
       "0       johnniemarg     9319     3.001225     3.949256      3.888750   \n",
       "1           Brolo75   207537     4.007071     4.033426      4.234354   \n",
       "2     Thehuntmaster    77779     2.012664     2.625627      2.248818   \n",
       "3         Citadel82    29977     4.015398     4.011260      4.489105   \n",
       "4          MattyG85   105784     4.360996     4.346861      4.247655   \n",
       "...             ...      ...          ...          ...           ...   \n",
       "5364            DIM    24905     3.897901     3.533755      3.897154   \n",
       "5365        mfnmbvp    16807     3.712364     3.905960      4.099634   \n",
       "5366    PhillyStyle    41505     3.146118     3.350885      3.221402   \n",
       "5367     davidperez    74804     3.981646     3.847039      3.844615   \n",
       "5368      eporter66     2751     4.083333     4.119048      4.000000   \n",
       "\n",
       "      taste_r_star  \n",
       "0         3.977268  \n",
       "1         4.222896  \n",
       "2         1.535139  \n",
       "3         4.471402  \n",
       "4         4.366067  \n",
       "...            ...  \n",
       "5364      4.072123  \n",
       "5365      4.294318  \n",
       "5366      3.078893  \n",
       "5367      3.707253  \n",
       "5368      4.095238  \n",
       "\n",
       "[5369 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000582b5-031e-4d26-894e-afb23b0c2067",
   "metadata": {},
   "source": [
    "# user-based-collaborative-filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5df6829-ebae-47ac-a84d-162b681e7c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\胖头鱼\\AppData\\Local\\Temp\\ipykernel_12772\\3335527731.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['overall_r_star'] = train_df[[f'{asp}_r_star' for asp in aspects]].mean(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>beer_id</th>\n",
       "      <th>feel_r_star</th>\n",
       "      <th>look_r_star</th>\n",
       "      <th>smell_r_star</th>\n",
       "      <th>taste_r_star</th>\n",
       "      <th>overall_r_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2beerdogs</td>\n",
       "      <td>286475</td>\n",
       "      <td>3.517751</td>\n",
       "      <td>3.760857</td>\n",
       "      <td>3.768435</td>\n",
       "      <td>3.551346</td>\n",
       "      <td>3.649597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scootny</td>\n",
       "      <td>138765</td>\n",
       "      <td>3.984384</td>\n",
       "      <td>3.733674</td>\n",
       "      <td>3.991600</td>\n",
       "      <td>4.099598</td>\n",
       "      <td>3.952314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boilermaker88</td>\n",
       "      <td>2280</td>\n",
       "      <td>1.989741</td>\n",
       "      <td>2.295181</td>\n",
       "      <td>1.553805</td>\n",
       "      <td>1.566540</td>\n",
       "      <td>1.851317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>altgeeky1</td>\n",
       "      <td>25007</td>\n",
       "      <td>2.417028</td>\n",
       "      <td>2.725218</td>\n",
       "      <td>1.784229</td>\n",
       "      <td>1.894806</td>\n",
       "      <td>2.205320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>draheim</td>\n",
       "      <td>46983</td>\n",
       "      <td>3.949314</td>\n",
       "      <td>4.175389</td>\n",
       "      <td>4.156928</td>\n",
       "      <td>4.191522</td>\n",
       "      <td>4.118288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21470</th>\n",
       "      <td>metter98</td>\n",
       "      <td>51153</td>\n",
       "      <td>4.079885</td>\n",
       "      <td>4.003453</td>\n",
       "      <td>4.388597</td>\n",
       "      <td>4.312034</td>\n",
       "      <td>4.195992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21471</th>\n",
       "      <td>Gunslinger711</td>\n",
       "      <td>34146</td>\n",
       "      <td>3.915641</td>\n",
       "      <td>3.866922</td>\n",
       "      <td>3.926612</td>\n",
       "      <td>4.017181</td>\n",
       "      <td>3.931589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21472</th>\n",
       "      <td>BEERchitect</td>\n",
       "      <td>9613</td>\n",
       "      <td>3.008361</td>\n",
       "      <td>3.226066</td>\n",
       "      <td>3.227799</td>\n",
       "      <td>3.004243</td>\n",
       "      <td>3.116617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21473</th>\n",
       "      <td>budgood1</td>\n",
       "      <td>31057</td>\n",
       "      <td>1.500929</td>\n",
       "      <td>1.270215</td>\n",
       "      <td>1.500857</td>\n",
       "      <td>1.504986</td>\n",
       "      <td>1.444247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21474</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>4137</td>\n",
       "      <td>4.009236</td>\n",
       "      <td>4.018068</td>\n",
       "      <td>3.530114</td>\n",
       "      <td>3.528699</td>\n",
       "      <td>3.771529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21475 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            username  beer_id  feel_r_star  look_r_star  smell_r_star  \\\n",
       "0          2beerdogs   286475     3.517751     3.760857      3.768435   \n",
       "1            scootny   138765     3.984384     3.733674      3.991600   \n",
       "2      Boilermaker88     2280     1.989741     2.295181      1.553805   \n",
       "3          altgeeky1    25007     2.417028     2.725218      1.784229   \n",
       "4            draheim    46983     3.949314     4.175389      4.156928   \n",
       "...              ...      ...          ...          ...           ...   \n",
       "21470       metter98    51153     4.079885     4.003453      4.388597   \n",
       "21471  Gunslinger711    34146     3.915641     3.866922      3.926612   \n",
       "21472    BEERchitect     9613     3.008361     3.226066      3.227799   \n",
       "21473       budgood1    31057     1.500929     1.270215      1.500857   \n",
       "21474      roadhouse     4137     4.009236     4.018068      3.530114   \n",
       "\n",
       "       taste_r_star  overall_r_star  \n",
       "0          3.551346        3.649597  \n",
       "1          4.099598        3.952314  \n",
       "2          1.566540        1.851317  \n",
       "3          1.894806        2.205320  \n",
       "4          4.191522        4.118288  \n",
       "...             ...             ...  \n",
       "21470      4.312034        4.195992  \n",
       "21471      4.017181        3.931589  \n",
       "21472      3.004243        3.116617  \n",
       "21473      1.504986        1.444247  \n",
       "21474      3.528699        3.771529  \n",
       "\n",
       "[21475 rows x 7 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects = ['feel', 'look', 'smell', 'taste']\n",
    "train_df['overall_r_star'] = train_df[[f'{asp}_r_star' for asp in aspects]].mean(axis=1)\n",
    "val_df  ['overall_r_star'] = val_df  [[f'{asp}_r_star' for asp in aspects]].mean(axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "609fdd3f-1864-4cd3-a49b-701c6b83d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Best RMSE score: 0.8162098633583126\n",
      "Best parameters: {'k': 20, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': True}}\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "#reader + load Dataset —\n",
    "reader = Reader(rating_scale=(train_df['overall_r_star'].min(),\n",
    "                              train_df['overall_r_star'].max()))\n",
    "data = Dataset.load_from_df(\n",
    "    train_df[['username','beer_id','overall_r_star']],\n",
    "    reader\n",
    ")\n",
    "\n",
    "#fine‐tune with GridSearchCV —\n",
    "param_grid = {\n",
    "    'k':       [5, 10, 20, 40],\n",
    "    'min_k':   [1, 2, 5],\n",
    "    'sim_options': {\n",
    "        'name':       ['pearson','cosine'],\n",
    "        'user_based': [True]\n",
    "    }\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    KNNBasic,\n",
    "    param_grid,\n",
    "    measures=['rmse'],\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "gs.fit(data)\n",
    "\n",
    "print(\"Best RMSE score:\",    gs.best_score['rmse'])\n",
    "print(\"Best parameters:\",    gs.best_params['rmse'])\n",
    "\n",
    "#build final Trainset and final algo with best params —\n",
    "trainset = data.build_full_trainset()\n",
    "best_opts = gs.best_params['rmse']\n",
    "algo = KNNBasic(\n",
    "    k=best_opts['k'],\n",
    "    min_k=best_opts['min_k'],\n",
    "    sim_options=best_opts['sim_options']\n",
    ")\n",
    "\n",
    "#fit on the full trainset —\n",
    "algo.fit(trainset)\n",
    "\n",
    "#prepare your val_test_list as before —\n",
    "val_test_list = list(\n",
    "    val_df[['username','beer_id','overall_r_star']]\n",
    "      .itertuples(index=False, name=None)\n",
    ")\n",
    "\n",
    "#finally test\n",
    "predictions = algo.test(val_test_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e698c93-ee16-458c-81eb-7888a862e84f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "492a0d55-46ec-4dd0-bd69-09ca47ed6a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAF0CAYAAABhWkCsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABMI0lEQVR4nO3de1xU1fo/8M+eAWa4CCqTgEAIKAqiqdBRLMsrhloeS7M0TcXUKMus0/HSNy9pdsoMu6iZFzJTybR+lZjRMW9pF00rS1NJQq46oKCTMjKzfn9wZsMwMwi4ZXT8vF8vXjLPrL33emYv9jyu2bO3JIQQICIiIlKQytkdICIiItfDAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg1zOkCFD4OnpiXPnzjlsM3LkSLi7u6OoqKjO65UkCbNnz5Yf79ixA5IkYceOHVdcdsyYMWjVqlWdt1XdkiVLkJaWZhPPzs6GJEl2n2sM27ZtQ2JiIlq2bAmNRoOWLVuiZ8+eeOWVVxq0vnXr1iE1NbXO7Xv27AlJkuQfT09P3HbbbUhNTYXZbG5QHxw5ePAg7r77bvj5+UGSpHr1k+hmxQKDXE5ycjIuXbqEdevW2X2+tLQUn3zyCQYNGoSAgIAGb6dLly7Yt28funTp0uB11IWjAiMoKAj79u3DwIEDr+n27Vm2bBnuuece+Pr64u2338a2bdvwn//8B9HR0fj4448btM76FhgAEBERgX379mHfvn1IT09HcHAwnnnmGUyfPr1BfXBk3LhxKCgowIYNG7Bv3z489NBDiq6fyBW5ObsDREpLSkpCy5YtsWrVKqSkpNg8v379ely8eBHJyclXtR1fX19069btqtZxNTQajdO2v2DBAtx11102xcSoUaMUnz2ojaenp9VrkJSUhHbt2uHtt9/GvHnz4O7u3uB1m0wmVFRUQKPR4PDhw3jssceQlJSkRLdx+fJlSJIENzcegsl1cQaDXI5arcajjz6KAwcO4Ndff7V5fvXq1QgKCkJSUhLOnDmDlJQUxMTEwMfHBy1atEDv3r2xe/fuK27H0UckaWlpaNu2LTQaDaKjo7FmzRq7y8+ZMwddu3ZF8+bN4evriy5dumDlypWofv/BVq1a4bfffsPOnTvljwIsH7U4+ohkz5496NOnD5o0aQIvLy90794dW7ZssemjJEn45ptv8Pjjj0On08Hf3x/3338/8vPzr5h7cXExgoKC7D6nUlkfVoQQWLJkCTp16gRPT080a9YMQ4cOxZ9//im36dmzJ7Zs2YK//vrL6mOP+nJ3d0dcXBz+/vtvnDlzBgBQWFiIiRMnIiQkBB4eHggPD8ecOXNQUVEhL2d5LV999VXMmzcP4eHh0Gg0WL16NSRJQkVFBZYuXWrTr8OHD2Pw4MFo1qwZtFotOnXqhPfff9+qT5Zx8sEHH+DZZ59FcHAwNBoNTpw4gTFjxsDHxwdHjx5F//794e3tjaCgIPljpu+++w533nknvL29ERUVZbPuuo5fS34LFy7EokWLEB4eDh8fHyQkJOC7776zeR2///573HvvvfD394dWq0VkZCSmTJli1eb48eMYMWIEWrRoIY/1d955p977jFyYIHJBx48fF5IkiSlTpljFf/vtNwFATJs2TQghxNGjR8Xjjz8uNmzYIHbs2CG++OILkZycLFQqlfjmm2+slgUgZs2aJT/+5ptvBACrdqtXrxYAxODBg8Xnn38u1q5dK1q3bi1CQ0NFWFiY1frGjBkjVq5cKTIzM0VmZqZ46aWXhKenp5gzZ47c5qeffhIRERGic+fOYt++fWLfvn3ip59+EkIIcfLkSQFArF69Wm6/Y8cO4e7uLuLi4kR6err49NNPRWJiopAkSWzYsMGmnxEREWLy5Mli27ZtYsWKFaJZs2aiV69eV3x9+/btK9zc3MSsWbPEoUOHREVFhcO2jz32mHB3dxfPPvus+PLLL8W6detEu3btREBAgCgsLJT3yx133CECAwPlPPft21drH+6++27Rvn17m3iXLl2Em5ub+Pvvv0VBQYH82r/77rvi66+/Fi+99JLQaDRizJgx8jKW1zI4OFj06tVLfPzxx+Krr74SP/zwg9i3b58AIIYOHWrVr6NHj4omTZqIyMhIsWbNGrFlyxbx8MMPCwDiP//5j7xuyzgJDg4WQ4cOFZ999pn44osvRHFxsXj00UeFh4eHiI6OFosXLxaZmZli7NixAoCYPn26iIqKEitXrhTbtm0TgwYNEgDE/v375XXXdfxa8mvVqpW45557xKeffio+/fRT0aFDB9GsWTNx7tw5ue2XX34p3N3dRceOHUVaWprYvn27WLVqlXjooYfkNr/99pvw8/MTHTp0EGvWrBFfffWVePbZZ4VKpRKzZ8+udb/RzYMFBrmsu+++W+h0OmE0GuXYs88+KwCIY8eO2V2moqJCXL58WfTp00cMGTLE6rkrFRgmk0m0bNlSdOnSRZjNZrlddna2cHd3tykwqjOZTOLy5cti7ty5wt/f32r59u3bi7vvvttmGXsFRrdu3USLFi3E+fPnrXKKjY0VISEh8notBUZKSorVOl999VUBQBQUFDjsqxBCnDhxQsTGxgoAAoDw9PQUffr0EW+//bbV6215c3799detlj916pTw9PQUzz//vBwbOHBgra9RTZYC4/Lly+Ly5csiPz9fTJs2TQAQw4YNE0IIMXHiROHj4yP++usvq2UXLlwoAIjffvtNCFH1WkZGRlr13wKAeOKJJ6xiDz30kNBoNCInJ8cqnpSUJLy8vOQ3bcs4ueuuu2zW++ijjwoAYtOmTXLs8uXL4pZbbhEA5GJSCCGKi4uFWq0WU6dOdfiaOBq/lvw6dOhgVQz+8MMPAoBYv369HIuMjBSRkZHi4sWLDrfTv39/ERISIkpLS63iTz75pNBqtaKkpMThsnTz4Eck5LKSk5Oh1+vx2WefAQAqKiqwdu1a9OjRA23atJHbLVu2DF26dIFWq4Wbmxvc3d3x3//+F0eOHKnX9v744w/k5+djxIgRVtPoYWFh6N69u0377du3o2/fvvDz84NarYa7uztefPFFFBcX4/Tp0/XO12Aw4Pvvv8fQoUPh4+Mjx9VqNUaNGoXc3Fz88ccfVsvcd999Vo87duwIAPjrr79q3VZkZCR+/vln7Ny5E3PmzEHfvn3x448/4sknn0RCQgIuXboEAPjiiy8gSRIeeeQRVFRUyD+BgYG47bbb6vQNnNr89ttvcHd3h7u7O1q2bInXX38dI0eOxHvvvSdvv1evXmjZsqXV9i3nUuzcudPm9ajreRvbt29Hnz59EBoaahUfM2YM/v77b+zbt88q/sADD9hdjyRJGDBggPzYzc0NrVu3RlBQEDp37izHmzdvjhYtWtjsm/qM34EDB0KtVsuPa+7vY8eOISsrC8nJydBqtXb7e+nSJfz3v//FkCFD4OXlZfW6DhgwAJcuXbL7sQvdfFhgkMsaOnQo/Pz8sHr1agBARkYGioqKrE7uXLRoER5//HF07doVmzZtwnfffYcff/wR99xzDy5evFiv7RUXFwMAAgMDbZ6rGfvhhx+QmJgIAHjvvffw7bff4scff8TMmTMBoN7bBoCzZ89CCGH33IiWLVta9dHC39/f6rFGo6nz9lUqFe666y68+OKL+Oyzz5Cfn4/hw4fjwIEDWLVqFQCgqKgIQggEBATIhYDl57vvvoNer693ntVFRkbixx9/xP79+3H48GGcO3cOa9euhZ+fn7z9zz//3Gbb7du3BwCb7Ts6r8QeR+ehOHqtHa3by8vL5s3cw8MDzZs3t2nr4eEhF29A/cfvlfa35byVkJAQu3215FVRUYG33nrL5nW1FEpXu1/JNfAUZnJZnp6eePjhh/Hee++hoKAAq1atQpMmTTBs2DC5zdq1a9GzZ08sXbrUatnz58/Xe3uWg3dhYaHNczVjGzZsgLu7O7744gurN5dPP/203tu1aNasGVQqFQoKCmyes5y4qdPpGrz+K/H29sb06dORnp6Ow4cPy9uTJAm7d++W38yqsxerD61Wi/j4eIfP63Q6dOzYEfPnz7f7vKUYsKjPiaX+/v71eq0bctLqlSg5fgHglltuAQDk5uY6bNOsWTN5VuyJJ56w2yY8PLxB2yfXwgKDXFpycjKWLVuG1157DRkZGRgzZgy8vLzk5yVJsnmT++WXX7Bv3z6bqe8radu2LYKCgrB+/XpMnTpVfkP566+/sHfvXqs3M8tXFKtPV1+8eBEffPCBzXo1Gk2dZhS8vb3RtWtXbN68GQsXLoSnpycAwGw2Y+3atQgJCUFUVFS9cnKkoKDA7v/ILdPyllwHDRqEV155BXl5eXjwwQdrXWdd86yPQYMGISMjA5GRkWjWrJmi6+7Tpw8++eQT5OfnW+3bNWvWwMvLq1G+Qqzk+AWAqKgoREZGYtWqVZg6dardAtDLywu9evXCwYMH0bFjR3h4eDS4/+Ta+BEJubT4+Hh07NgRqampuHz5ss21LwYNGoSvvvoKs2bNwvbt27F06VL079+/Qf8DU6lUeOmll3DgwAEMGTIEW7ZswYcffoi+ffvafEQycOBAXLhwASNGjEBmZiY2bNiAHj162D2gd+jQAT///DPS09Px448/2v3qrcWCBQtQXFyMXr164eOPP8Znn32GAQMG4PDhw1i4cKFi/4tu3749hg0bhlWrVmHnzp3Ytm0b5s6di4kTJyIgIEB+ne+44w5MmDABY8eOxfPPP48vvvgC33zzDdatW4eUlBSr/3l36NABp0+fxtKlS/HDDz9g//79V93PuXPnwt3dHd27d8fSpUuxfft2ZGRkYMmSJRg0aFCt/1O/klmzZsHd3R29evXChx9+iK1bt+KRRx7Bli1bMHv2bPljmmtJyfFr8c477+Cvv/5Ct27dsGbNGuzYsQNr1qzByJEj5TaLFy9GTk4OevTogbS0NOzYsQOff/453njjDfTu3VuJ1MgVOPssU6JrbfHixQKAiImJsXmuvLxcPPfccyI4OFhotVrRpUsX8emnn4pHH33U5hsNqMPXVIUQYsWKFaJNmzbCw8NDREVFiVWrVtld36pVq0Tbtm2FRqMRERERYsGCBWLlypUCgDh58qTcLjs7WyQmJoomTZoIAPJ67H2LRAghdu/eLXr37i28vb2Fp6en6Natm/j888+t2li+RfLjjz9axR3lVNO7774r7r//fhERESG8vLyEh4eHiIyMFJMmTRKnTp2yab9q1SrRtWtXuU+RkZFi9OjRVl+5LCkpEUOHDhVNmzYVkiSJKx2eHH1NtaYzZ86Ip556SoSHhwt3d3fRvHlzERcXJ2bOnCkuXLgghKh6LV977TW764Cdb5EIIcSvv/4q7r33XuHn5yc8PDzEbbfdZrM/LK/pxo0bbZZ/9NFHhbe3d51zCwsLEwMHDpQf13X81pZfzXEtROW3f5KSkoSfn5/QaDQiMjJSPPPMM1ZtTp48KcaNGyeCg4OFu7u7uOWWW0T37t3FvHnzbLZBNydJiGpX9SEiIiJSAD8iISIiIsWxwCAiRaxbtw5dunSBp6cnmjdvjqFDh+L48eMO21suoe3op/ol0B21eeGFF+Q2ly9fRmpqKjp06ABvb2/odDqMHDnyqs6zIKKG47dIiOiqLV++HBMnTgRQ+RXF4uJibNq0Cbt27cKhQ4dsvg4KVN4srmvXrlaxoqIiZGdnA7B/3YhOnTpZnQhb/ZsSjz32mHyvjvbt26OwsBDr1q3Dt99+i59//rlRTrokoio8B4OIrkp5eTmCg4NRXFyMBx54AB9//DHy8/PRrl07nD9/Hk8++STeeuutOq1r0KBB2LJlC9q2bYsjR47I33qx/Hvy5En5Zm/VnT9/Hs2aNYPJZMKzzz6LhQsX4ty5cwgJCYHBYMD8+fMxY8YMxXImoivjRyREdFX2798vX7XScjnsli1byteB2LZtW53Wc+TIEWRkZAAAnn32WbtfqY2Pj4eXlxfat2+PBQsWoLy8HEDlHVstt4m3LFf9rq5ff/11Q1IjoqvAAoOIrsqpU6fk31u0aCH/HhAQAADIycmp03oWLlwIIQRatGiBUaNG2Tyv0+kQEhICjUaD33//HTNmzMDo0aMBVH7cYrlM9cKFC9GhQwdERkbCYDAAAPLy8hqWHBE12E13DobZbEZ+fj6aNGlyTS7dS3Sz+fvvv+XfDQYDysrKAABGoxFA5YyCJeZIUVERPvzwQwDAhAkTYDQa5eWByhuLxcXFydsbPnw4du3ahY8++gizZs1CSEgIlixZgvnz52PLli34888/0blzZ4SEhODQoUNQq9VX7AMRXZkQAufPn0fLli2tZgntuenOwcjNzW3QJXSJiIio0qlTp2q9KR5wE85gNGnSBEDli+Pr6+vk3hDd+IxGI9q2bYuSkhLce++9WLt2LfLz83H77bfjwoULmDhxIl599VX5pmQTJkzAhAkT5OUNBgNiYmJw7tw5TJgwAa+99prV+r/99lucOXMG9913H1QqFS5duoThw4fLt3o/cuQIWrZsiaNHj0Kn08k3GUtNTcWsWbMAAGlpaRgyZEgjvBpErq2srAyhoaHye2ltbroCw/KxiK+vLwsMIoUsWLAAEydOxOeff45OnTqhuLgYFy5cgE6nw4svvghfX1/5mhgXLlyw+ttLS0vDuXPnoFar8e9//9vm77KoqAhjx46Ft7c3IiIikJubi7NnzwIAxo4di3bt2gEAdu3ahRkzZqB169YoLS2V72o6ZMgQjB49mh+JEimoLn9PPMmTiK7ahAkTsHbtWnTq1An5+fmQJAn333+/zV1kazKZTEhNTQUA3H///YiIiLBpc+edd2LSpEkIDQ3FyZMnYTabERcXh2XLlmH58uVyu9jYWMTGxiI3Nxd6vR7t27fHq6++io8++ojFBZET3HTnYJSVlcHPzw+lpaWcwSAiIqqH+ryHcgaDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFHfT3eyM6EbUatoWZ3eBrqHsVwY6uwtEiuMMBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpzukFxpIlSxAeHg6tVou4uDjs3r3bYdsxY8ZAkiSbn/bt2zdij4mIiOhKnFpgpKenY8qUKZg5cyYOHjyIHj16ICkpCTk5OXbbL168GAUFBfLPqVOn0Lx5cwwbNqyRe05ERES1cWqBsWjRIiQnJ2P8+PGIjo5GamoqQkNDsXTpUrvt/fz8EBgYKP/s378fZ8+exdixYxu550RERFQbpxUYRqMRBw4cQGJiolU8MTERe/furdM6Vq5cib59+yIsLOxadJGIiIgayM1ZG9br9TCZTAgICLCKBwQEoLCw8IrLFxQUYOvWrVi3bl2t7crLy1FeXi4/LisrAwCYTCaYTCYAgCRJUKlUMJvNEELIbR3FVSoVJElyGLest3ocAMxmc53iarUaQgiruKUvjuJ17TtzujFzUkuVz5kFICDJjy1qjwNqySoMkwAkACqbuAQJol5xFQSkanEBwCwkqCSB6s2FAMz17vvNkZNl31+PY696X1zl74k5NTyn+nBagWEhSdZ/3UIIm5g9aWlpaNq0Kf75z3/W2m7BggWYM2eOTTwrKws+Pj4AKj96CQoKQlFREUpLS+U2Op0OOp0OeXl5MBgMcjwwMBBNmzZFdnY2jEajHA8JCYGPjw+ysrKsdkp4eDjc3Nxw/Phxqz60adMGFRUVOHnypBxTqVSIioqCwWBAbm6uHPfw8EBERARKS0utCjBvb2+EhoaipKQEer1ejjMn18qpX3BlPw+fVSHXACS0EPBxrzp47NeroL8E9AoScFNVxfcUqnDRBHl5i8w8FTzVwJ2BVfEKs4Sv8yX4a4F4XVX8wmUJe4okBHsDsc2q4vpLEvbrJUT4CrT2rdpmrkHC4bMSYpoKhHhXxU+USThRJqGzv4BOWxVnTpUzutfr2LNwpb8n5tTwnAIDA1FXkqhe4jQio9EILy8vbNy4EUOGDJHjTz/9NA4dOoSdO3c6XFYIgaioKAwaNAhvvPFGrduxN4Nh2Ym+vr4Arr8K0RWrXuZ0dTlFvbC1sg/8375L5nTi5YGVz1+HY696X1zl74k5NTwng8EAPz8/lJaWyu+hjjhtBsPDwwNxcXHIzMy0KjAyMzMxePDgWpfduXMnTpw4geTk5CtuR6PRQKPR2MTVajXUarVVzPKC1lTfeM31NiQuSVK94kr1nTldnzmZhPW7YM3HV47bxoTDuFSvuBlS5cpqxuvdx5s3J8us7fU49uoav5H+nuoaZ06O43Xh1I9Ipk6dilGjRiE+Ph4JCQlYvnw5cnJyMGnSJADA9OnTkZeXhzVr1lgtt3LlSnTt2hWxsbHO6DYRERFdgVMLjOHDh6O4uBhz585FQUEBYmNjkZGRIX8rpKCgwOaaGKWlpdi0aRMWL17sjC4TERFRHTjtHAxnKSsrq/PnR0TXi1bTtji7C3QNZb8y0NldIKqT+ryHOv1S4UREROR6WGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQEdF1bd26dejSpQs8PT3RvHlzDB061ObmXPacPHkSY8aMQVBQEDw8PBAQEICBAwda3TRs8uTJuO222+Dm5gZJkuzezGv9+vX4xz/+AX9/f3h4eCAoKAgDBgzArl27FM3T1Tj9bqpERESOLF++HBMnTgRQeefP4uJibNq0Cbt27cKhQ4fQsmVLu8sdO3YM3bt3R3FxMby8vBAdHQ2j0YjMzEycP38efn5+AIAPPvgAHh4eaN68Oc6cOWN3Xd9//z2ys7MREhICIQSOHDmCrVu34ptvvsGRI0fQqlWra5L7jY4zGEREdF0qLy/HjBkzAAAPPPAA/vzzTxw5cgRNmjTBmTNnsGDBAofLPvXUUyguLkavXr2Ql5eHn3/+GUeOHEFpaanVLMWvv/6K06dPY8CAAQ7X9corr+D06dP4+eef8csvv2DZsmUAgEuXLuHAgQMKZet6WGAQEdF1af/+/SguLgZQWWAAQMuWLdGtWzcAwLZt2+wud/bsWXz11VcAgGbNmiE+Ph5NmjRBt27dsGfPHri5VU3eh4aGXrEfWq0WP/74I7p164aOHTvi8ccfl+Px8fENT9DFscAgIqLr0qlTp+TfW7RoIf8eEBAAADY3w7Q4fvw4LLfZ2rx5M8xmM7RaLb7//nskJSXh+++/r3dfSktL8f333+PXX3/F5cuXccstt2Dbtm3yzTnJFgsMIiK6Ljm6F6clLkmS3ecrKirk3/v27YusrCycOHECzZs3h8lkwtKlS+vdl759+0IIgcLCQjz99NM4c+YMRo4c6bDIIRYYRER0nbr11lvl34uKiuTfT58+DcDxxxvBwcHy7/Hx8ZAkCX5+foiKigIAZGdnN7hPAQEBmDt3LgAgNzdXPh+DbLHAICKi69Ltt98Of39/AMCmTZsAAHl5edi3bx8A4J577gEAtGvXDu3atcPbb78NAAgLC0ObNm0AAAcOHIAQAmVlZTh27BgAyM/V1TvvvAODwSA/3rJli/x79ThZY4FBRETXJQ8PD7z88ssAKs+liIiIQExMDC5cuACdTodp06YBAP744w/88ccf0Ov18rKvvPIKJElCZmYmWrdujdatW6OkpATe3t6YOnWq3K5nz55o3bo1Nm/eDADQ6/Vye8u5Gk8++SSaN2+OmJgYtGnTBiNGjAAAuLm5yb+TLRYYRER03ZowYQLWrl2LTp06IT8/H5Ik4f7778fevXsdXgMDAO6//358+umnuP3225Gfnw+VSoV//vOf2L9/P6Kjo+V22dnZyMrKwvnz5wEAJpMJWVlZyMrKwsWLFwEAY8aMQatWrZCTk4Ps7GwEBgZiyJAh2L17N7p27XptX4AbmCQcnUXjosrKyuDn54fS0lL4+vo6uztEddJq2pYrN6IbVvYrA53dBaI6qc97KGcwiIiISHEsMIiIiEhxLDCIiIhIcSwwbjINuSvhmDFjIEmSzU9ISMgV21h+LNLS0hy2OXHixDXLm4iIGhfvpnoTaehdCS2Cg4Otiorql+6NjIy0OZv68OHDMBgM8mV9q2vSpAliYmKsYlqttt45ERHR9YkFxk2i5l0JP/74Y+Tn56Ndu3byXQnfeuutWtcxfvx4zJ492+5z//d//4f/+7//kx/n5+cjPDwcQOVdDWvq0qULduzY0bBkiIjousePSG4SDb0rYXWpqanQaDQIDQ3FQw89hKysLIdt33zzTRiNRnh7e8t3Hqzuhx9+gI+PD3Q6HXr16oVvvvmmIWkREdF1igXGTaKhdyW00Gq18kckubm5SE9Px+233468vDybthcuXMC7774LAEhOTkazZs2snlepVAgKCkKrVq1w7tw57NixA3369LG6/C4REd3YWGDcJBp6V0IA+Ne//gW9Xo/ffvsNWVlZ8s19zp49i9WrV9u0f++993Du3Dmo1Wo888wzVs/17t0beXl5yMrKwuHDh7F//354enpCCIE33nijoekREdF1hudg3CQaeldCAGjfvr3V45EjR2LSpEkAbGc+KioqsHjxYgDAsGHD0KpVK4f9AIBOnTohJiYGBw4c4G2PiRoZrxDr+px5lVinz2AsWbIE4eHh0Gq1iIuLw+7du2ttX15ejpkzZyIsLAwajQaRkZFYtWpVI/X2xtXQuxICwKxZs6xuIrRhwwb595oFxEcffYS//voLAPDcc8/Z9OOdd97B77//Lj/+5Zdf5Mc110VERDcup85gpKenY8qUKViyZAnuuOMOvPvuu0hKSsLvv/9u8z9diwcffBBFRUVYuXIlWrdujdOnT6OioqKRe37jsdyVcOLEifJdCYuLi+3elRCAVUExd+5czJs3DxERERBCyCd3BgYGYvz48Vbbef311wEAvXr1QlxcnE0/Nm7ciCeffBJBQUHw9/fH0aNHUVFRATc3N7kPRER043PqDMaiRYuQnJyM8ePHIzo6GqmpqQgNDcXSpUvttv/yyy+xc+dOZGRkoG/fvmjVqhX+8Y9/oHv37o3c8xtTQ+9KOH/+fCQkJKC0tBS5ublo3bo1Jk2ahP3791udMLp9+3b89NNPAOzPXgCVtz0eNGgQ1Go1jh8/joCAANx3333Yu3cvevfurWzCRETkNE67m6rRaISXlxc2btyIIUOGyPGnn34ahw4dws6dO22WSUlJwbFjxxAfH48PPvgA3t7euO+++/DSSy/B09PT7nbKy8tRXl4uPy4rK0NoaChKSkrkO8FJkgSVSgWz2Wx1MqSjuEqlgiRJDuMmk8mqDypVZR1nNpvrFFer1RBCWMUtfXEUr2vfmdONmVPUC1sr+yAAAQlqyfrPtvY4oK5xDq9JABIAlU1cggRRr7gKAtXPERYAzEKCShKo3lwIwFzvvt8cOZ14ufJz8sYeexEztnI/uXhOx+YlAVDuuGcwGOp8N1WnfUSi1+thMplsrvIYEBCAwsJCu8v8+eef2LNnD7RaLT755BPo9XqkpKSgpKTE4XkYCxYswJw5c2ziWVlZ8PHxAQD4+fkhKCgIRUVFKC0tldvodDrodDrk5eXBYDDI8cDAQDRt2hTZ2dkwGo1yPCQkBD4+PsjKyrLaKeHh4XBzc7O5JHebNm1QUVGBkydPyjGVSoWoqCgYDAbk5ubKcQ8PD0RERKC0tNTq9fH29pYLpuofazAn18qpX3BlPw+fVSHXACS0EPBxrzqw7NeroL8E9AoScFNVxfcUqnDRBHl5i8w8FTzVwJ2BVfEKs4Sv8yX4a4F4XVX8wmUJe4okBHsDsc2q4vpLEvbrJUT4CrT2rdpmrkHC4bMSYpoKhHhXxU+USThRJqGzv4BOWxVnTpX/4XLG2APA/eTiOVnGlFLHvcDAQNSV02Yw8vPzERwcjL179yIhIUGOz58/Hx988AGOHj1qs0xiYiJ2796NwsJC+Y9j8+bNGDp0KAwGg91ZDM5gMCdXyIkzGK6dE2cwboz9dCPmdFPOYOh0OqjVapvZitOnT9u9dwUABAUFITg4WC4uACA6OhpCCOTm5qJNmzY2y2g0Gmg0Gpu4Wq2GWq22ille0JrqG6+53obEJUmqV1ypvjOn6zMnk7A+EtV8fOW4bUw4jEv1ipshVa6sZrzefbx5c7Jch8YZY4/7ybVzqjkWlDju1ZXTTvL08PBAXFwcMjMzreKZmZkOT9q84447kJ+fjwsXLsixY8eOQaVSWd2Ei4iIiJzLqd8imTp1KlasWIFVq1bhyJEjeOaZZ5CTkyNfxGn69OkYPXq03H7EiBHw9/fH2LFj8fvvv2PXrl3417/+hXHjxjk8yZOIiIgan1OvgzF8+HAUFxdj7ty5KCgoQGxsLDIyMhAWFgYAKCgosLq6o4+PDzIzMzF58mTEx8fD398fDz74IObNm+esFIiIiMgOp18qPCUlBSkpKXafS0tLs4m1a9fO5mMVIiIiur44/VLhRERE5HpYYBAREZHiWGAQERGR4px+DoYr4a2PXZszb3tMRHSj4QwGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESmOBQYREREpjgUGERERKY4FBhERESnO6QXGkiVLEB4eDq1Wi7i4OOzevdth2x07dkCSJJufo0ePNmKPiYiI6EqcWmCkp6djypQpmDlzJg4ePIgePXogKSkJOTk5tS73xx9/oKCgQP5p06ZNI/WYiIiI6sKpBcaiRYuQnJyM8ePHIzo6GqmpqQgNDcXSpUtrXa5FixYIDAyUf9RqdSP1mIiIiOrCaQWG0WjEgQMHkJiYaBVPTEzE3r17a122c+fOCAoKQp8+ffDNN99cy24SERFRA7g5a8N6vR4mkwkBAQFW8YCAABQWFtpdJigoCMuXL0dcXBzKy8vxwQcfoE+fPtixYwfuuusuu8uUl5ejvLxcflxWVgYAMJlMMJlMAABJkqBSqWA2myGEkNs6iqtUKkiSZNseAgIS1FJVDADMAhAA1JJ130wCkACobOISJIh6xVUQkKrFBQCzkKCSBKo3FwIwO+xjfeM3V06W8WKhVqshhIDZbJZjljHjKF7XMVYzbukr95Nr5mTZ99XHDFB5rLEXV2rsAeB+cvGcLMcty/tWzeOYozHmKF4fTiswLCTJ+hUWQtjELNq2bYu2bdvKjxMSEnDq1CksXLjQYYGxYMECzJkzxyaelZUFHx8fAICfnx+CgoJQVFSE0tJSuY1Op4NOp0NeXh4MBoMcDwwMRNOmTZGdnQ2j0SjH/bWA/hLQK0jATVW10/cUqnDRBPQLtt5RmXkqeKqBOwOr4hVmCV/nS/DXAvG6qviFyxL2FEkI9gZim1XF9Zck7NdLiPAVaO1btc1cg4TDZyXENBUI8a6KnyiTcKJMQmd/AZ22Kn74rAq5BiChhYCPe1V8v17FnP6X0/Hjx+WYSqVCVFQUDAYDcnNz5biHhwciIiJQWlpqVSh7e3sjNDQUJSUl0Ov1cryuY8/SJ+4n18zJaDTCzc3NaowBQJs2bVBRUYGTJ0/KMSXHHgDuJxfPyTKmQkJC4OPjg6ysLKuiITw8vF5jLzAwEHUlieolbSMyGo3w8vLCxo0bMWTIEDn+9NNP49ChQ9i5c2ed1jN//nysXbsWR44csfu8vRkMyx+br68vAOVmMFrP3OoyVW/d4jdXTifmJ1nFG3MGI+qFrdckJ1fcTzdiTideHlj5fCPPYETM2Mr95OI5HZtXedxSagbDYDDAz88PpaWl8nuoI06bwfDw8EBcXBwyMzOtCozMzEwMHjy4zus5ePAggoKCHD6v0Wig0Whs4mq12ubkUMsLWlNd45bdbxL2Z2BMdko54TAu1StuhlS5sppxh31RKm6vj66Zk72TiSVJqle8oWOsZl+5n1wrJ8usraMT1q/l2ON+cu2cao6F+oyx2uJ14dSPSKZOnYpRo0YhPj4eCQkJWL58OXJycjBp0iQAwPTp05GXl4c1a9YAAFJTU9GqVSu0b98eRqMRa9euxaZNm7Bp0yZnpkFEREQ1OLXAGD58OIqLizF37lwUFBQgNjYWGRkZCAsLAwAUFBRYXRPDaDTiueeeQ15eHjw9PdG+fXts2bIFAwYMcFYKREREZIfTT/JMSUlBSkqK3efS0tKsHj///PN4/vnnG6FXREREdDWcfqlwIiIicj0sMIiIiEhxLDCIiIhIcSwwiIiISHEsMIiIiEhxLDCIiIhIcSwwiIiISHEsMIiIiEhxLDCIiIhIcSwwiIiISHEsMIiIiEhxLDCIiIhIcSwwiIiISHEsMIiIiEhxLDCIiIhIcSwwiIiISHEsMIiIiEhxLDCIiIhIcSwwiIiISHH1LjAqKirg5uaGw4cPX4v+EBERkQuod4Hh5uaGsLAwmEyma9EfIiIicgEN+ojkhRdewPTp01FSUqJ0f4iIiMgFuDVkoTfffBMnTpxAy5YtERYWBm9vb6vnf/rpJ0U6R0RERDemBhUY//znPxXuBhEREbmSBhUYs2bNUrofRERE5EIaVGBYHDhwAEeOHIEkSYiJiUHnzp2V6hcRERHdwBpUYJw+fRoPPfQQduzYgaZNm0IIgdLSUvTq1QsbNmzALbfconQ/iYiI6AbSoG+RTJ48GWVlZfjtt99QUlKCs2fP4vDhwygrK8NTTz2ldB+JiIjoBtOgAuPLL7/E0qVLER0dLcdiYmLwzjvvYOvWrfVa15IlSxAeHg6tVou4uDjs3r27Tst9++23cHNzQ6dOneq1PSIiIrr2GlRgmM1muLu728Td3d1hNpvrvJ709HRMmTIFM2fOxMGDB9GjRw8kJSUhJyen1uVKS0sxevRo9OnTp959JyIiomuvQQVG79698fTTTyM/P1+O5eXl4ZlnnqnXm/6iRYuQnJyM8ePHIzo6GqmpqQgNDcXSpUtrXW7ixIkYMWIEEhISGtJ9IiIiusYaVGC8/fbbOH/+PFq1aoXIyEi0bt0a4eHhOH/+PN566606rcNoNOLAgQNITEy0iicmJmLv3r0Ol1u9ejWysrL4VVkiIqLrWIO+RRIaGoqffvoJmZmZOHr0KIQQiImJQd++feu8Dr1eD5PJhICAAKt4QEAACgsL7S5z/PhxTJs2Dbt374abW926Xl5ejvLycvlxWVkZAMBkMsn3U5EkCSqVCmazGUIIua2juEqlgiRJtu0hICBBLVXFAMAsAAFALVn3zSQACYDKJi5BgqhXXAUBqVpcADALCSpJoHpzIQCzwz7WN35z5VTz/jtqtRpCCKuPBS1jxlG8rmOsZtzSV+4n18zJsu9rfsSsUqnsxpUaewC4n1w8J8txy/K+VfM45miMOYrXR70LjIqKCmi1Whw6dAj9+vVDv379GrxxoGqQWwghbGJA5Ys0YsQIzJkzB1FRUXVe/4IFCzBnzhybeFZWFnx8fAAAfn5+CAoKQlFREUpLS+U2Op0OOp0OeXl5MBgMcjwwMBBNmzZFdnY2jEajHPfXAvpLQK8gATdV1U7fU6jCRRPQL9h6R2XmqeCpBu4MrIpXmCV8nS/BXwvE66riFy5L2FMkIdgbiG1WFddfkrBfLyHCV6C1b9U2cw0SDp+VENNUIMS7Kn6iTMKJMgmd/QV02qr44bMq5BqAhBYCPu5V8f16FXP6X07Hjx+XYyqVClFRUTAYDMjNzZXjHh4eiIiIQGlpqVWh7O3tjdDQUJSUlECv18vxuo49S5+4n1wzJ6PRCDc3N6sxBgBt2rRBRUUFTp48KceUHHsAuJ9cPCfLmAoJCYGPjw+ysrKsiobw8PB6jb3AwEDUlSSql7R1FBkZic2bN+O2226r76Iyo9EILy8vbNy4EUOGDJHjTz/9NA4dOoSdO3datT937hyaNWsGtVotx+T/3anV+Oqrr9C7d2+b7dibwbD8sfn6+gJQbgaj9cytLlP11i1+c+V0Yn6SVbwxZzCiXth6TXJyxf10I+Z04uWBlc838gxGxIyt3E8untOxeZXHLaVmMAwGA/z8/FBaWiq/hzrSoI9ILHdTXbt2LZo3b96QVcDDwwNxcXHIzMy0KjAyMzMxePBgm/a+vr749ddfrWJLlizB9u3b8fHHHyM8PNzudjQaDTQajU1crVZbFStA1QtaU13jlt1vErYzMJVx25hwGJfqFTdDqlxZzbjDvigVt9dH18yp5ngBKg/S9Yk3dIzV7Cv3k2vlZJm1tTdmHMWVGnvcT66dU82xUJ8xVlu8Lpx6N9WpU6di1KhRiI+PR0JCApYvX46cnBxMmjQJADB9+nTk5eVhzZo1UKlUiI2NtVq+RYsW0Gq1NnEiIiJyLqfeTXX48OEoLi7G3LlzUVBQgNjYWGRkZCAsLAwAUFBQcMVrYhAREdH1p0EneQLAuHHjEBoaetUdSElJQUpKit3n0tLSal129uzZmD179lX3gYiIiJRV7+tguLm5YeHChTYnihARERFZNOhCW3369MGOHTsU7goRERG5igadg5GUlITp06fj8OHDiIuLsznJ87777lOkc0RERHRjalCB8fjjjwOovJdITfa+Z0tEREQ3lwYVGFdz6VAiIiJyffU6B2PAgAFWlzOeP38+zp07Jz8uLi5GTEyMYp0jIiKiG1O9Coxt27ZZXXb7P//5D0pKSuTHFRUV+OOPP5TrHREREd2Q6lVg1LxtSQNuY0JEREQ3gQZ9TZWIiIioNvUqMCRJsrmVur1bqxMREdHNrV7fIhFCYMyYMfLdSS9duoRJkybJ18Gofn4GERER3bzqVWA8+uijVo8feeQRmzajR4++uh4RERHRDa9eBcbq1auvVT+IiIjIhfAkTyIiIlIcCwwiIiJSHAsMIiIiUhwLDCIiIlIcCwwiIiJSHAsMIiIiUhwLDCIiIlIcCwwiIiJSHAsMIiIiUhwLDCIiIlIcCwwiIiJSHAsMIiIiUhwLDCIiIlIcCwwiIiJSHAsMIiIiUpzTC4wlS5YgPDwcWq0WcXFx2L17t8O2e/bswR133AF/f394enqiXbt2eOONNxqxt0RERFQXbs7ceHp6OqZMmYIlS5bgjjvuwLvvvoukpCT8/vvvuPXWW23ae3t748knn0THjh3h7e2NPXv2YOLEifD29saECROckAERERHZ49QZjEWLFiE5ORnjx49HdHQ0UlNTERoaiqVLl9pt37lzZzz88MNo3749WrVqhUceeQT9+/evddaDiIiIGp/TZjCMRiMOHDiAadOmWcUTExOxd+/eOq3j4MGD2Lt3L+bNm+ewTXl5OcrLy+XHZWVlAACTyQSTyQQAkCQJKpUKZrMZQgi5raO4SqWCJEm27SEgIEEtVcUAwCwAAUAtWffNJAAJgMomLkGCqFdcBQGpWlwAMAsJKkmgenMhALPDPtY3fnPlZBkvFmq1GkIImM1mOWYZM47idR1jNeOWvnI/uWZOln1ffcwAlccae3Glxh4A7icXz8ly3LK8b9U8jjkaY47i9eG0AkOv18NkMiEgIMAqHhAQgMLCwlqXDQkJwZkzZ1BRUYHZs2dj/PjxDtsuWLAAc+bMsYlnZWXBx8cHAODn54egoCAUFRWhtLRUbqPT6aDT6ZCXlweDwSDHAwMD0bRpU2RnZ8NoNMpxfy2gvwT0ChJwU1Xt9D2FKlw0Af2CrXdUZp4KnmrgzsCqeIVZwtf5Evy1QLyuKn7hsoQ9RRKCvYHYZlVx/SUJ+/USInwFWvtWbTPXIOHwWQkxTQVCvKviJ8oknCiT0NlfQKetih8+q0KuAUhoIeDjXhXfr1cxp//ldPz4cTmmUqkQFRUFg8GA3NxcOe7h4YGIiAiUlpZajWNvb2+EhoaipKQEer1ejtd17Fn6xP3kmjkZjUa4ublZjTEAaNOmDSoqKnDy5Ek5puTYA8D95OI5WcZUSEgIfHx8kJWVZVU0hIeH12vsBQYGoq4kUb2kbUT5+fkIDg7G3r17kZCQIMfnz5+PDz74AEePHnW47MmTJ3HhwgV89913mDZtGt5++208/PDDdtvam8Gw/LH5+voCUG4Go/XMrS5T9dYtfnPldGJ+klW8MWcwol7Yek1ycsX9dCPmdOLlgZXPN/IMRsSMrdxPLp7TsXmVxy2lZjAMBgP8/PxQWloqv4c64rQZDJ1OB7VabTNbcfr0aZtZjZrCw8MBAB06dEBRURFmz57tsMDQaDTQaDQ2cbVaDbVabRWzvKA11TVu2f0mIdlrDpOdUk44jEv1ipshVa6sZtxhX5SK2+uja+ZUc7wAlQfp+sQbOsZq9pX7ybVysnxcYW/MOIorNfa4n1w7p5pjoT5jrLZ4XTjtJE8PDw/ExcUhMzPTKp6ZmYnu3bvXeT1CCKsZCiIiInI+p35NderUqRg1ahTi4+ORkJCA5cuXIycnB5MmTQIATJ8+HXl5eVizZg0A4J133sGtt96Kdu3aAai8LsbChQsxefJkp+VAREREtpxaYAwfPhzFxcWYO3cuCgoKEBsbi4yMDISFhQEACgoKkJOTI7c3m82YPn06Tp48CTc3N0RGRuKVV17BxIkTnZUCERER2eHUAgMAUlJSkJKSYve5tLQ0q8eTJ0/mbAUREdENwOmXCiciIiLXwwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTHAoOIiIgUxwKDiIiIFMcCg4iIiBTn9AJjyZIlCA8Ph1arRVxcHHbv3u2w7ebNm9GvXz/ccsst8PX1RUJCArZt29aIvSUiIqK6cGqBkZ6ejilTpmDmzJk4ePAgevTogaSkJOTk5Nhtv2vXLvTr1w8ZGRk4cOAAevXqhXvvvRcHDx5s5J4TERFRbZxaYCxatAjJyckYP348oqOjkZqaitDQUCxdutRu+9TUVDz//PO4/fbb0aZNG7z88sto06YNPv/880buOREREdXGaQWG0WjEgQMHkJiYaBVPTEzE3r1767QOs9mM8+fPo3nz5teii0RERNRAbs7asF6vh8lkQkBAgFU8ICAAhYWFdVrH66+/DoPBgAcffNBhm/LycpSXl8uPy8rKAAAmkwkmkwkAIEkSVCoVzGYzhBByW0dxlUoFSZJs20NAQIJaqooBgFkAAoBasu6bSQASAJVNXIIEUa+4CgJStbgAYBYSVJJA9eZCAGaHfaxv/ObKyTJeLNRqNYQQMJvNcswyZhzF6zrGasYtfeV+cs2cLPu++pgBKo819uJKjT0A3E8unpPluGV536p5HHM0xhzF68NpBYaFJFm/wkIIm5g969evx+zZs/H//t//Q4sWLRy2W7BgAebMmWMTz8rKgo+PDwDAz88PQUFBKCoqQmlpqdxGp9NBp9MhLy8PBoNBjgcGBqJp06bIzs6G0WiU4/5aQH8J6BUk4Kaq2ul7ClW4aAL6BVvvqMw8FTzVwJ2BVfEKs4Sv8yX4a4F4XVX8wmUJe4okBHsDsc2q4vpLEvbrJUT4CrT2rdpmrkHC4bMSYpoKhHhXxU+USThRJqGzv4BOWxU/fFaFXAOQ0ELAx70qvl+vYk7/y+n48eNyTKVSISoqCgaDAbm5uXLcw8MDERERKC0ttSqUvb29ERoaipKSEuj1ejle17Fn6RP3k2vmZDQa4ebmZjXGAKBNmzaoqKjAyZMn5ZiSYw8A95OL52QZUyEhIfDx8UFWVpZV0RAeHl6vsRcYGIi6kkT1krYRGY1GeHl5YePGjRgyZIgcf/rpp3Ho0CHs3LnT4bLp6ekYO3YsNm7ciIEDB9a6HXszGJY/Nl9fXwDKzWC0nrnVZareusVvrpxOzE+yijfmDEbUC1uvSU6uuJ9uxJxOvFx5HGvsGYyIGVu5n1w8p2PzKo9bSs1gGAwG+Pn5obS0VH4PdcRpMxgeHh6Ii4tDZmamVYGRmZmJwYMHO1xu/fr1GDduHNavX3/F4gIANBoNNBqNTVytVkOtVlvFLC9oTXWNW3a/SdifgTHZKeWEw7hUr7gZUuXKasYd9kWpuL0+umZONccLUHmQrk+8oWOsZl+5n1wrJ8usrb0x4yiu1NjjfnLtnGqOhfqMsdrideHUj0imTp2KUaNGIT4+HgkJCVi+fDlycnIwadIkAMD06dORl5eHNWvWAKgsLkaPHo3FixejW7du8jSgp6enPN1HREREzufUAmP48OEoLi7G3LlzUVBQgNjYWGRkZCAsLAwAUFBQYHVNjHfffRcVFRV44okn8MQTT8jxRx99FGlpaY3dfSIiInLA6Sd5pqSkICUlxe5zNYuGHTt2XPsOERER0VVz+qXCiYiIyPWwwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsU5vcBYsmQJwsPDodVqERcXh927dztsW1BQgBEjRqBt27ZQqVSYMmVK43WUiIiI6sypBUZ6ejqmTJmCmTNn4uDBg+jRoweSkpKQk5Njt315eTluueUWzJw5E7fddlsj95aIiIjqyqkFxqJFi5CcnIzx48cjOjoaqampCA0NxdKlS+22b9WqFRYvXozRo0fDz8+vkXtLREREdeW0AsNoNOLAgQNITEy0iicmJmLv3r1O6hUREREpwc1ZG9br9TCZTAgICLCKBwQEoLCwULHtlJeXo7y8XH5cVlYGADCZTDCZTAAASZKgUqlgNpshhJDbOoqrVCpIkmTbHgICEtRSVQwAzAIQANSSdd9MApAAqGziEiSIesVVEJCqxQUAs5CgkgSqNxcCMDvsY33jN1dOlvFioVarIYSA2WyWY5Yx4yhe1zFWM27pK/eTa+Zk2ffVxwxQeayxF1dq7AHgfnLxnCzHLcv7Vs3jmKMx5iheH04rMCwkyfoVFkLYxK7GggULMGfOHJt4VlYWfHx8AAB+fn4ICgpCUVERSktL5TY6nQ46nQ55eXkwGAxyPDAwEE2bNkV2djaMRqMc99cC+ktAryABN1XVTt9TqMJFE9Av2HpHZeap4KkG7gysileYJXydL8FfC8TrquIXLkvYUyQh2BuIbVYV11+SsF8vIcJXoLVv1TZzDRIOn5UQ01QgxLsqfqJMwokyCZ39BXTaqvjhsyrkGoCEFgI+7lXx/XoVc/pfTsePH5djKpUKUVFRMBgMyM3NleMeHh6IiIhAaWmpVaHs7e2N0NBQlJSUQK/Xy/G6jj1Ln7ifXDMno9EINzc3qzEGAG3atEFFRQVOnjwpx5QcewC4n1w8J8uYCgkJgY+PD7KysqyKhvDw8HqNvcDAQNSVJKqXtI3IaDTCy8sLGzduxJAhQ+T4008/jUOHDmHnzp21Lt+zZ0906tQJqamptbazN4Nh+WPz9fUFoNwMRuuZW12m6q1b/ObK6cT8JKt4Y85gRL2w9Zrk5Ir76UbM6cTLAyufb+QZjIgZW7mfXDynY/Mqj1tKzWAYDAb4+fmhtLRUfg91xGkzGB4eHoiLi0NmZqZVgZGZmYnBgwcrth2NRgONRmMTV6vVUKvVVjHLC1pTXeOW3W8S9mdgTHZKOeEwLtUrboZUubKacYd9USpur4+umVPN8QJUHqTrE2/oGKvZV+4n18rJMmtrb8w4iis19rifXDunmmOhPmOstnhdOPUjkqlTp2LUqFGIj49HQkICli9fjpycHEyaNAkAMH36dOTl5WHNmjXyMocOHQIAXLhwAWfOnMGhQ4fg4eGBmJgYZ6RAREREdji1wBg+fDiKi4sxd+5cFBQUIDY2FhkZGQgLCwNQeWGtmtfE6Ny5s/z7gQMHsG7dOoSFhSE7O7sxu05ERES1cPpJnikpKUhJSbH7XFpamk3MSaeMEBERUT04/VLhRERE5HpYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeJYYBAREZHiWGAQERGR4lhgEBERkeKcXmAsWbIE4eHh0Gq1iIuLw+7du2ttv3PnTsTFxUGr1SIiIgLLli1rpJ4SERFRXTm1wEhPT8eUKVMwc+ZMHDx4ED169EBSUhJycnLstj958iQGDBiAHj164ODBg5gxYwaeeuopbNq0qZF7TkRERLVxaoGxaNEiJCcnY/z48YiOjkZqaipCQ0OxdOlSu+2XLVuGW2+9FampqYiOjsb48eMxbtw4LFy4sJF7TkRERLVxc9aGjUYjDhw4gGnTplnFExMTsXfvXrvL7Nu3D4mJiVax/v37Y+XKlbh8+TLc3d1tlikvL0d5ebn8uLS0FABw9uxZmEwmAIAkSVCpVDCbzRBCyG0dxVUqFSRJsomLcgMEJKilqhgAmAUgAKgl676ZBCABUNnEJUgQ9YqrICBViwsAZiFBJQlUby4EYHbYx/rGb66czp49axVXq9UQQsBsNssxy5hxFK/rGKsZl4yGa5KTK+6nGzEny3Gp+pgBKo819uJKjT1z+d/cTy6ek+W4ZXnfsrzvWTgaY47iBoPhf9u33q49Tisw9Ho9TCYTAgICrOIBAQEoLCy0u0xhYaHd9hUVFdDr9QgKCrJZZsGCBZgzZ45NvFWrVg3vPN2Umqc6uwfkqpq+4ewekKtqfo3G1vnz5+Hn51drG6cVGBaSZF3CCSFsYldqby9uMX36dEydOlV+bDabUVJSAn9//1q3Q7UrKytDaGgoTp06BV9fX2d3h1wIxxZdKxxbV08IgfPnz6Nly5ZXbOu0AkOn00GtVtvMVpw+fdpmlsIiMDDQbns3Nzf4+/vbXUaj0UCj0VjFmjZt2vCOkxVfX1/+odI1wbFF1wrH1tW50syFhdNO8vTw8EBcXBwyMzOt4pmZmejevbvdZRISEmzaf/XVV4iPj7d7/gURERE5h1O/RTJ16lSsWLECq1atwpEjR/DMM88gJycHkyZNAlD58cbo0aPl9pMmTcJff/2FqVOn4siRI1i1ahVWrlyJ5557zlkpEBERkR1OPQdj+PDhKC4uxty5c1FQUIDY2FhkZGQgLCwMAFBQUGB1TYzw8HBkZGTgmWeewTvvvIOWLVvizTffxAMPPOCsFG5aGo0Gs2bNsvn4iehqcWzRtcKx1bgkUZfvmhARERHVg9MvFU5ERESuhwUGERERKY4FBhERESmOBQYREREpjgUGAQDGjBkDSZLkrwhXl5KSAkmSMGbMGACVFzebOHEibr31Vmg0GgQGBqJ///7Yt2+fvEyrVq0gSZLNzyuvvNJYKZETWMaRJElwc3PDrbfeiscff9zqPi6WsbFhwwab5du3bw9JkpCWlibHDh48iEGDBqFFixbQarVo1aoVhg8fDr1eDwDIzs62O9YkScJ33313zXMm56jPMcti7969UKvVuOeee2yW4ThSHgsMkoWGhmLDhg24ePGiHLt06RLWr1+PW2+9VY498MAD+Pnnn/H+++/j2LFj+Oyzz9CzZ0+UlJRYrc/y9ePqP5MnT260fMg57rnnHhQUFCA7OxsrVqzA559/jpSUFKs2oaGhWL16tVXsu+++Q2FhIby9veXY6dOn0bdvX+h0Omzbtk2+/k1QUBD+/vtvq+W//vprm/EWFxd37RIlp6vrMcti1apVmDx5Mvbs2WN1CYTqOI6U4/R7kdD1o0uXLvjzzz+xefNmjBw5EgCwefNmhIaGIiIiAgBw7tw57NmzBzt27MDdd98NAAgLC8M//vEPm/U1adIEgYGBjZcAXRcss1oAEBISguHDh1vNSADAyJEj8cYbb+DUqVMIDQ0FUHnwHzlyJNasWSO327t3L8rKyrBixQq4uVUersLDw9G7d2+b7fr7+3O83WTqcsyyMBgM+Oijj/Djjz+isLAQaWlpePHFF23WyXGkHM5gkJWxY8da/c9y1apVGDdunPzYx8cHPj4++PTTT1FeXu6MLtIN5M8//8SXX35pcyn/gIAA9O/fH++//z4A4O+//0Z6errVWAMq7z9UUVGBTz75pE63h6abz5WOWRbp6elo27Yt2rZti0ceeQSrV6/mmLrGWGCQlVGjRmHPnj3Izs7GX3/9hW+//RaPPPKI/LybmxvS0tLw/vvvo2nTprjjjjswY8YM/PLLLzbr+ve//y0XJJafHTt2NGI25AxffPEFfHx84OnpicjISPz+++/497//bdNu3LhxSEtLgxACH3/8MSIjI9GpUyerNt26dcOMGTMwYsQI6HQ6JCUl4bXXXkNRUZHN+rp3724z3kwm07VKk64TVzpmWaxcuVKO33PPPbhw4QL++9//2rTjOFIOPyIhKzqdDgMHDsT7778PIQQGDhwInU5n1eaBBx7AwIEDsXv3buzbtw9ffvklXn31VaxYscLqpKp//etfNidZBQcHN0IW5Ey9evXC0qVL8ffff2PFihU4duyY3XNvBg4ciIkTJ2LXrl0O/9cJAPPnz8fUqVOxfft2fPfdd1i2bBlefvll7Nq1Cx06dJDbpaenIzo62mpZtVqtbHJ03anLMeuPP/7ADz/8gM2bNwOo/I/S8OHDsWrVKvTt29eqLceRclhgkI1x48bhySefBAC88847dttotVr069cP/fr1w4svvojx48dj1qxZVgWFTqdD69atG6PLdB3x9vaW9/ubb76JXr16Yc6cOXjppZes2rm5uWHUqFGYNWsWvv/+e3zyyScO1+nv749hw4Zh2LBhWLBgATp37oyFCxfKH7EAlSf8cbzdnK50zFq5ciUqKiqs/oMjhIC7uzvOnj2LZs2ayXGOI+XwIxKycc8998BoNMJoNKJ///51WiYmJgYGg+Ea94xuRLNmzcLChQuRn59v89y4ceOwc+dODB482OogXxsPDw9ERkZyvJGstmNWRUUF1qxZg9dffx2HDh2Sf37++WeEhYXhww8/dFKvXR9nMMiGWq3GkSNH5N+rKy4uxrBhwzBu3Dh07NgRTZo0wf79+/Hqq69i8ODBVm3Pnz+PwsJCq5iXlxd8fX2vbQJ0XenZsyfat2+Pl19+GW+//bbVc9HR0dDr9fDy8rK77BdffIENGzbgoYceQlRUFIQQ+Pzzz5GRkWHzNdfi4mKb8da0aVNotVplE6LrTm3HrC+++AJnz55FcnIy/Pz8rJ4bOnQoVq5cKc9+ABxHSmKBQXY5KgJ8fHzQtWtXvPHGG8jKysLly5cRGhqKxx57DDNmzLBq++KLL9p8DWzixIlYtmzZNes3XZ+mTp2KsWPH2j3Z09/f3+FyMTEx8PLywrPPPotTp05Bo9GgTZs2WLFiBUaNGmXVtuZn6QCwfv16PPTQQ1efAF33HB2zVq5cib59+9oUF0Dl+WQvv/wyfvrpJzRv3hwAx5GSeLt2IiIiUhzPwSAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsWxwCAiIiLFscAgIiIixbHAICIiIsX9f4bHatKhQVRHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from surprise.accuracy import mse, rmse, mae\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mse_score  = mse(predictions, verbose=False)\n",
    "rmse_score = rmse(predictions, verbose=False)\n",
    "mae_score  = mae(predictions, verbose=False)\n",
    "\n",
    "metrics = ['MSE','RMSE','MAE']\n",
    "scores  = [mse_score, rmse_score, mae_score]\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.bar(metrics, scores)\n",
    "for i, v in enumerate(scores):\n",
    "    ax.text(i, v + 0.02, f\"{v:.3f}\", ha='center', va='bottom', fontweight='bold')\n",
    "ax.set_ylabel(\"Error\"); ax.set_title(\"Validation Set Performance\")\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e3ad0489-3fbe-441c-bfed-2b70887e8b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-5 recommendations for Boilermaker88:\n",
      "  Beer 179485: 4.811\n",
      "  Beer 18850: 4.761\n",
      "  Beer 91860: 4.759\n",
      "  Beer 80653: 4.705\n",
      "  Beer 1144: 4.703\n",
      "\n",
      "Top-5 recommendations for budgood1:\n",
      "  Beer 1144: 4.703\n",
      "  Beer 61361: 4.702\n",
      "  Beer 44743: 4.693\n",
      "  Beer 111616: 4.665\n",
      "  Beer 107838: 4.618\n",
      "\n",
      "Top-5 recommendations for draheim:\n",
      "  Beer 44743: 4.693\n",
      "  Beer 47088: 4.689\n",
      "  Beer 77227: 4.683\n",
      "  Beer 47546: 4.606\n",
      "  Beer 54351: 4.580\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "def recommend_user(algo, trainset, user_id, N=5):\n",
    "    \"\"\"\n",
    "    Returns a list of (item_id, estimated_score) for the top-N\n",
    "    items the user has not yet rated.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inner_uid = trainset.to_inner_uid(user_id)\n",
    "    except ValueError:\n",
    "        return []  # user not in trainset\n",
    "\n",
    "    # items the user has already rated\n",
    "    seen_iids = {iid for (iid, _) in trainset.ur[inner_uid]}\n",
    "    # map all internal iids back to raw ids\n",
    "    raw_iids = [trainset.to_raw_iid(i) for i in trainset.all_items()]\n",
    "\n",
    "    # candidates = those the user hasn't seen\n",
    "    candidates = [iid for iid in raw_iids if trainset.to_inner_iid(iid) not in seen_iids]\n",
    "\n",
    "    # predict each candidate\n",
    "    scores = [(iid, algo.predict(user_id, iid).est) for iid in candidates]\n",
    "    # sort by score descending and take top N\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:N]\n",
    "\n",
    "for user in ['Boilermaker88', 'budgood1', 'draheim']:\n",
    "    top5 = recommend_user(algo, trainset, user, N=5)\n",
    "    print(f\"\\nTop-5 recommendations for {user}:\")\n",
    "    for beer_id, score in top5:\n",
    "        print(f\"  Beer {beer_id}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1d403-eaae-4569-8808-159a59d74c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
